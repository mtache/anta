{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#anta-documentation","title":"ANTA Documentation","text":"<p>This website provides generic documentation related to the Arista Network Test Automation framework (ANTA)</p> <p></p>"},{"location":"#arista-network-test-automation-anta-framework","title":"Arista Network Test Automation (ANTA) Framework","text":"<p>This repository is a Python package to automate tests on Arista devices.</p> <ul> <li>The package name is ANTA, which stands for Arista Network Test Automation.</li> <li>This package provides a set of tests to validate the state of your network.</li> <li>This package can be imported in Python scripts:<ul> <li>To automate NRFU (Network Ready For Use) test on a preproduction network</li> <li>To automate tests on a live network (periodically or on demand)</li> </ul> </li> </ul> <p>This repository comes with a set of scripts to run Arista Network Test Automation (ANTA) framework</p> <ul> <li><code>check-devices.py</code> is an easy to use script to test your network with ANTA.</li> <li><code>collect-eos-commands.py</code> to collect commands output from devices</li> <li><code>collect-sheduled-show-tech.py</code> to collect the scheduled show tech-support files from devices</li> </ul> <p>In addition you have also some useful scripts to help around testing:</p> <ul> <li><code>clear-counters.py</code> to clear counters on devices</li> <li><code>evpn-blacklist-recovery.py</code> to clear the list of MAC addresses which are blacklisted in EVPN</li> <li><code>create-devices-inventory-from-cvp.py</code>: Build inventory for scripts from Arista Cloudvision (CVP)</li> </ul> <p>Most of these scripts use eAPI (EOS API). You can find examples of EOS automation with eAPI in this repository.</p>"},{"location":"contribution/","title":"Contributions","text":""},{"location":"contribution/#how-to-contribute-to-anta","title":"How to contribute to ANTA","text":"<p>Warning</p> <p>Still a work in progress, feel free to reach out to the team.</p>"},{"location":"contribution/#install-repository","title":"Install repository","text":"<p><code>python setup.py install</code> is used to install packages that you\u2019re not going to modify yourself. If you want to install the package and then be able to edit the code without having to re-install the package every time for the changes take effect, you can use <code>python setup.py develop</code></p> <p>you can also use <code>pip install -e .</code> The <code>.</code> refers to the current working directory (the directory where is the setup.py file). The <code>-e</code> flag specifies that we want to install in editable mode, which means that when we edit the files in our package we do not need to re-install the package before the changes come into effect. You will need to reload the package though!</p> <p>Run these commands to install:</p> <ul> <li>The package ANTA and its dependencies</li> <li>These scripts and the packages they required</li> </ul> <pre><code>git clone https://github.com/arista-netdevops-community/network-test-automation.git\ncd network-test-automation\n</code></pre> <pre><code>python setup.py develop\n</code></pre> <p>or</p> <pre><code>pip install -e .\n</code></pre> <p>Run these commands to verify:</p> <pre><code>pip list\ncheck-devices-reachability.py --help\nwhich check-devices-reachability.py\n</code></pre>"},{"location":"contribution/#clone-install-package-requirements","title":"Clone &amp; Install package requirements","text":"<p>Run these commands to install the packages indicated in the requirements.txt file.</p> <pre><code># Clone repository\ngit clone https://github.com/arista-netdevops-community/network-test-automation.git\n\n# Enter into the repository\ncd network-test-automation\n\n# Install requirements\npip install -r requirements.txt\n</code></pre> <p>These packages are required by:</p> <ul> <li>These scripts</li> <li>The package ANTA</li> </ul> <p>But this will not install:</p> <ul> <li>The ANTA package</li> <li>These scripts</li> </ul> <p>Run this command to verify:</p> <pre><code># Check ANTA has been installed in your python path\npip list | grep anta\n\n# Check scripts are in your $PATH\ncheck-devices-reachability.py --help\n\n# Find where the script is located\nwhich check-devices-reachability.py\n</code></pre>"},{"location":"contribution/#install-dev-requirements","title":"Install dev requirements","text":"<p>Run the following command to install all required packages for the development process.</p> <pre><code># Install dev requirements\npip install -r requirements-dev.txt\n\n# Install pre-commit hook\npre-commit install\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#getting-started","title":"Getting Started","text":"<p>This section shows how to use ANTA with basic configuration.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>The easiest way to intall ANTA package is to run Python (<code>&gt;=3.7</code>) and its pip package to install:</p> <pre><code>pip install \\\ngit+https://github.com/arista-netdevops-community/network-test-automation.git\n</code></pre> <p>For more details about how to install package, please see the requirements and intallation section.</p>"},{"location":"getting-started/#configure-arista-eos-devices","title":"Configure Arista EOS devices","text":"<p>First, you need to configure your management interface</p> <pre><code>vrf instance MGMT\n!\ninterface Management1\n   description oob_management\n   vrf MGMT\n   ip address 10.73.1.105/24\n!\n</code></pre> <p>Then, configure access to eAPI:</p> <pre><code>!\nmanagement api http-commands\n   protocol https port 443\n   no shutdown\n   vrf MGMT\n      no shutdown\n   !\n!\n</code></pre>"},{"location":"getting-started/#create-your-inventory","title":"Create your inventory","text":"<p>First, we need to list devices we want to test. You can create a file manually with this format:</p> <pre><code>anta_inventory:\nhosts:\n- host: 10.73.1.105\n</code></pre>"},{"location":"getting-started/#test-catalog","title":"Test Catalog","text":"<p>To test your network, it is important to define a test catalog to list all the tests to run against your inventory. Test catalog references python functions into a yaml file. This file can be loaded by anta.loader.py</p> <p>The structure to follow is like:</p> <pre><code>&lt;anta_tests_submodule&gt;:\n- &lt;anta_tests_submodule function name&gt;:\n&lt;test function option&gt;:\n&lt;test function option value&gt;\n</code></pre> <p>Here is an example for basic things:</p> <pre><code># Load anta.tests.software\nsoftware:\n- verify_eos_version: # Verifies the device is running one of the allowed EOS version.\nversions: # List of allowed EOS versions.\n- 4.25.4M\n- 4.26.1F\n\n# Load anta.tests.system\nsystem:\n- verify_uptime: # Verifies the device uptime is higher than a value.\nminimum: 1\n\n# Load anta.tests.configuration\nconfiguration:\n- verify_zerotouch: # Verifies ZeroTouch is disabled.\n- verify_running_config_diffs:\n</code></pre>"},{"location":"getting-started/#test-your-network","title":"Test your network","text":"<p>To test EOS devices, this package comes with a generic script to run tests in your network. It requires an inventory file as well as a test catalog.</p> <p>This script has multiple options to manage test coverage and reporting.</p> <pre><code>python scripts/check-devices.py -h\n\noptional arguments:\n  -h, --help            show this help message and exit\n--inventory INVENTORY, -i INVENTORY\n                        ANTA Inventory file\n  --catalog CATALOG, -c CATALOG\n                        ANTA Tests catalog\n  --username USERNAME, -u USERNAME\n                        EOS Username\n  --password PASSWORD, -p PASSWORD\n                        EOS Password\n  --enable_password ENABLE_PASSWORD, -e ENABLE_PASSWORD\n                        EOS Enable Password\n  --timeout TIMEOUT, -t TIMEOUT\n                        eAPI connection timeout\n  --hostip HOSTIP       search result for host\n  --test TEST           search result for test\n--tags TAGS           List of device tags to limit scope of testing\n  --list                Display internal data\n  --json                Display data in json format\n  --table               Result represented in tables\n  --save SAVE           Save output to file. Only valid for --list and --json\n  --all-results         Display all test cases results. Default table view (Only valid with --table)\n--by-host             Provides summary of test results per device (Only valid with --table)\n--by-test             Provides summary of test results per test case (Only valid with --table)\n</code></pre> <p>Default output is a table format listing all test results, and it can be changed to a report per test case or per host</p>"},{"location":"getting-started/#default-report","title":"Default report","text":"<pre><code>$ check-devices.py -i .personal/avd-lab.yml -c .personal/ceos-catalog.yml --table\n\n                             All tests results\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Device IP     \u2503 Test Name              \u2503 Test Status \u2503 Message(s)       \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 10.73.252.11  \u2502 verify_mlag_interfaces \u2502 success     \u2502                  \u2502\n\u2502 10.73.252.12  \u2502 verify_mlag_interfaces \u2502 success     \u2502                  \u2502\n\u2502 10.73.252.102 \u2502 verify_mlag_interfaces \u2502 skipped     \u2502 MLAG is disabled \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/#report-per-test-case","title":"Report per test case","text":"<pre><code>$ check-devices.py -i .personal/avd-lab.yml -c .personal/ceos-catalog.yml --table --by-test --test verify_mlag_status\n\n                                              Summary per test case\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Test Case          \u2503 # of success \u2503 # of skipped \u2503 # of failure \u2503 # of errors \u2503 List of failed or error nodes \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 verify_mlag_status \u2502 8            \u2502 13           \u2502 0            \u2502 0           \u2502 []                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/#report-per-host","title":"Report per host","text":"<pre><code>$ check-devices.py -i .personal/avd-lab.yml -c .personal/ceos-catalog.yml --table --by-host --test verify_mlag_status --hostip 10.73.252.21\n\n                                            Summary per host\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Host IP      \u2503 # of success \u2503 # of skipped \u2503 # of failure \u2503 # of errors \u2503 List of failed ortest case \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 10.73.252.21 \u2502 0            \u2502 1            \u2502 0            \u2502 0           \u2502 []                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>You can find more information under the usage section of the website</p>"},{"location":"requirements-and-installation/","title":"Installation","text":""},{"location":"requirements-and-installation/#anta-requirements","title":"ANTA Requirements","text":""},{"location":"requirements-and-installation/#python-version","title":"Python version","text":"<p>Python 3 (<code>&gt;=3.7</code> and <code>=&lt;3.10</code>) is required:</p> <pre><code>python --version\nPython 3.9.9\n</code></pre>"},{"location":"requirements-and-installation/#install-anta-package","title":"Install ANTA package","text":"<p>This installation will deploy tests collection, scripts and all their Python requirements.</p> <p>The ANTA package and the scripts require some packages that are not part of the Python standard library. They are indicated in the requirements.txt file</p> <p>There are several ways to installt the ANTA and the scripts and the requirements. This is described below.</p> <p>Run this command to install:</p> <ul> <li>The package ANTA and its dependencies</li> <li>These scripts and packages they required</li> </ul> <pre><code>pip install git+https://github.com/arista-netdevops-community/network-test-automation.git\n</code></pre> <p>You can even specify the commit you would like to install.</p> <p>Run these commands to verify:</p> <pre><code># Check ANTA has been installed in your python path\npip list | grep anta\n\n# Check scripts are in your $PATH\ncheck-devices-reachability.py --help\n\n# Find where the script is located\nwhich check-devices-reachability.py\n</code></pre> <p>To update, simply run pip with <code>-U</code> option:</p> <pre><code>pip install -U git+https://github.com/arista-netdevops-community/network-test-automation.git\n</code></pre>"},{"location":"requirements-and-installation/#eos-requirements","title":"EOS Requirements","text":"<pre><code>configure\n!\nvrf instance MGMT\n!\ninterface Management1\n   description oob_management\n   vrf MGMT\n   ip address 10.73.1.105/24\n!\nend\n</code></pre> <p>Enable eAPI on the MGMT vrf:</p> <pre><code>configure\n!\nmanagement api http-commands\n   protocol https port 443\n   no shutdown\n   vrf MGMT\n      no shutdown\n!\nend\n</code></pre> <p>Now the swicth accepts on port 443 in the MGMT VRF HTTPS requests containing a list of CLI commands.</p> <p>Run these EOS commands to verify:</p> <pre><code>switch1#show management http-server\n</code></pre> <pre><code>switch1#show management api http-commands\n</code></pre>"},{"location":"usage-as-python-lib/","title":"ANTA as python lib","text":""},{"location":"usage-as-python-lib/#how-to-use-anta-as-a-python-library","title":"How to use ANTA as a Python Library","text":"<p>ANTA has been built to allow user to embeded its tools in your own application. This section describes how you can leverage ANTA modules to help you create your own NRFU solution.</p>"},{"location":"usage-as-python-lib/#inventory-manager","title":"Inventory Manager","text":"<p>Inventory class is in charge of creating a list of hosts with their information and an eAPI session ready to be consummed. To do that, it connects to all devices to check reachability and ensure eAPI is running.</p> <pre><code>from anta.inventory import AntaInventory\n\ninventory = AntaInventory(\n    inventory_file=\"inventory.yml\",\n    username=\"username\",\n    password=\"password\",\n    enable_password=\"enable\",\n    auto_connect=True,\n    timeout=1,\n)\n</code></pre> <p>Then it is easy to get all devices or only active devices with the following method:</p> <pre><code># print the non reachable devices\nfor device in inventory.get_inventory(established_only=False):\n    if device.established is False:\n        print(f\"Could not connect to device {device.host}\")\n\n# run an EOS commands list on the reachable devices from the inventory\nfor device in inventory.get_inventory(established_only=True):\n    device.session.runCmds(\n        1, [\"show version\", \"show ip bgp summary\"]\n    )\n</code></pre> <p>You can find data model for anta.inventory.AntaInventory in the auto-generated documentation.</p> How to create your inventory file <p>Please visit this dedicated section for how to use inventory and catalog files.</p>"},{"location":"usage-as-python-lib/#use-tests-from-anta","title":"Use tests from ANTA","text":"<p>All the test functions are based on the exact same input and returns a generic structure with different information.</p>"},{"location":"usage-as-python-lib/#test-input","title":"Test input","text":"<p>Any test input is based on an <code>InventoryDevice</code> object and a list of options. Here is an example to check uptime and check it is higher than <code>minimum</code> option.</p> <pre><code>def verify_uptime(device: InventoryDevice, minimum: int = None) -&gt; TestResult:\n</code></pre> <p>In general, <code>InventoryDevice</code> is an object created by <code>AntaInventory</code>. But it can be manually generated by following required data model.</p> <p>Here is an example of a list of <code>InventoryDevice</code></p> <pre><code>[\n    {\n        \"InventoryDevice(host=IPv4Address('192.168.0.17')\",\n        \"username='ansible'\",\n        \"password='ansible'\",\n        \"session=&lt;ServerProxy for ansible:ansible@192.168.0.17/command-api&gt;\",\n        \"url='https://ansible:ansible@192.168.0.17/command-api'\",\n        \"established=True\",\n        \"is_online=True\",\n        \"hw_model=cEOS-LAB\",\n    },\n\n    {\n        \"InventoryDevice(host=IPv4Address('192.168.0.2')\",\n        \"username='ansible'\",\n        \"password='ansible'\",\n        \"session=None\",\n        \"url='https://ansible:ansible@192.168.0.2/command-api'\",\n        \"established=False\"\n        \"is_online=False\",\n        \"tags\": ['dc1', 'spine', 'pod01'],\n        \"hw_model=unset\",\n    }\n]\n</code></pre>"},{"location":"usage-as-python-lib/#test-output","title":"Test output","text":"<p>All tests return a TestResult structure with the following elements:</p> <ul> <li><code>result</code>: Can be <code>success</code>, <code>skipped</code>, <code>failure</code>, <code>error</code> and report result of the test</li> <li><code>host</code>: IP address of the tested device</li> <li><code>test</code>: Test name runs on <code>host</code></li> <li><code>message</code>: Optional message returned by the test.</li> </ul>"},{"location":"usage-as-python-lib/#test-structure","title":"Test structure","text":"<p>All tests are based on this structure:</p> <pre><code>from anta.inventory.models import InventoryDevice\nfrom anta.result_manager.models import TestResult\nfrom anta.test import anta_test\n\n# Use the decorator that wraps the function and inject result argument\n@anta_test\nasync def &lt;test name&gt;(device: InventoryDevice, result: TestResut, &lt;list of args&gt;, minimum: int) -&gt; TestResult:\n\"\"\"\n    dosctring desccription\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        result (TestResult): TestResult instance for the test, injected\n                             automatically by the anta_test decorator.\n        minimum (int): example of test with int parameter\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the `minimum` parameter is  missing\n        * result = \"success\" if uptime is greater than minimun\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    # Test if options are valid (optional)\n    if not minimum:\n        result.is_skipped(\"verify_uptime was not run as no minimum were given\")\n        return result\n\n    # Use await for the remote device call\n    response = await device.session.cli(command=\"show uptime\", ofmt=\"json\")\n    # Add a debug log entry\n    logger.debug(f'query result is: {response}')\n\n    response_data = response[\"upTime\"]\n    # Check conditions on response_data\n    # ...\n\n    # Return data to caller\n    return result\n</code></pre>"},{"location":"usage-as-python-lib/#get-test-function-documentation","title":"Get test function documentation","text":"<p>Open an interactive python shell and run following commands:</p> <pre><code>&gt;&gt;&gt; from anta.tests.system import *\n\n&gt;&gt;&gt; help(verify_ntp)\n\nHelp on function verify_ntp in module anta.tests.system:\n\nverify_ntp(device: anta.inventory.models.InventoryDevice) -&gt; anta.result_manager.models.TestResult\n    Verifies NTP is synchronised.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if synchronized with NTP server\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n&gt;&gt;&gt; exit()\n</code></pre> <p>If you need to expose test description, you can use this workaround:</p> <pre><code>from anta.tests.system import *\n\nprint(f'{verify_ntp.__doc__.split(\"\\n\")[0]}')\n</code></pre>"},{"location":"usage-check-devices/","title":"Check Devices","text":""},{"location":"usage-check-devices/#how-to-use-anta-scripts","title":"How to use ANTA scripts","text":"<p>ANTA comes with some scripts to leverage network testing immediatly or if you don\u2019t want to create your own application. This page describes how to use <code>check-devices.py</code> script to run your network testing.</p> Create inventory &amp; tests catalog <p>Please visit this dedicated section for how to use inventory and catalog files.</p>"},{"location":"usage-check-devices/#check-devices-script","title":"Check devices script","text":"<p>The <code>check-devices.py</code> script comes with a number of options you can use for the testing. Some are mandatory where some others are optionals.</p>"},{"location":"usage-check-devices/#required-options","title":"Required options","text":""},{"location":"usage-check-devices/#specify-inventory-and-test-catalog","title":"Specify inventory and test catalog","text":"<p>There is no default file for inventory and tests catalog, so you have to provide paths in CLI using following triggers:</p> <pre><code>check-devices.py -i .personal/avd-lab.yml \\\n-c .personal/ceos-catalog.yml\n</code></pre>"},{"location":"usage-check-devices/#specify-username-and-password","title":"Specify username and password","text":"<p>The script needs your credentials to connect to devices and they have to be provided in the CLI directly. So it is easy to execute this script in a CI pipeline by sending secrets using an environment variable.</p> <pre><code>check-devices.py -i .personal/avd-lab.yml \\\n-c .personal/ceos-catalog.yml \\\n--username admin \\\n--password admin123\n</code></pre>"},{"location":"usage-check-devices/#specify-output-format","title":"Specify output format","text":"<p>Since this script can be used for human reporting or within a more complete scenario, user is free to select either <code>table</code>, <code>list</code> or <code>json</code> output format.</p> <pre><code>check-devices.py -i .personal/avd-lab.yml \\\n-c .personal/ceos-catalog.yml \\\n--username admin \\\n--password admin123 \\\n--(table|list|json)\n</code></pre> <p>This <code>--table</code> option provides a nice human readable format where <code>--list</code> is more a grepable output and <code>--json</code> is more to send output to another script</p> <p></p>"},{"location":"usage-check-devices/#available-options","title":"Available options","text":"<p>Then, besides the mandatory keys, some options are available such as:</p> <ul> <li>Tag (<code>--tag</code>): to run tests against a subset of your inventory.</li> <li>Timeout (<code>--timeout</code>): if some devices are not close to your tester, it might be useful to increase response delay.</li> <li>Enable Password (<code>--enable_password</code>): Allow to configure optional <code>enable</code> password required for some tests.</li> <li>Run tests for a specific host (<code>--hostip</code>)</li> <li>Run tests for a specific test (<code>--test</code>)</li> </ul> <p>Also, when you use <code>--table</code> for output, you can get some report summaries:</p> <ul> <li>Per host overview (<code>--by-host</code>): list number of sucessful, skipped, failed tests and list all failed tests.</li> </ul> <p></p> <ul> <li>Per test overview (<code>--by-test</code>): list number of sucessful, skipped, failed hosts and list all failed hosts.</li> </ul> <p></p> <ul> <li>Save JSON format to a file: use the <code>--save &lt;path/to/output/file.json&gt;</code> option.</li> </ul> <pre><code># Run testing\ncheck-devices.py -i .personal/avd-lab.yml \\\n-c .personal/ceos-catalog.yml \\\n--username admin \\\n--password admin123 \\\n--(table|list|json)\n\n# Display saved results\nhead -n 8 demo.json\n[\n{\n\"host\": \"10.73.252.11\",\n        \"test\": \"verify_eos_version\",\n        \"result\": \"failure\",\n        \"messages\": \"[\\\"device is running version 4.27.2F-26069621.4272F (engineering build) not in expected versions: ['4.25.4M', '4.26.1F']\\\"]\"\n},\n</code></pre>"},{"location":"usage-inventory-catalog/","title":"Inventory & Tests catalog","text":""},{"location":"usage-inventory-catalog/#inventory-catalog-definition","title":"Inventory &amp; Catalog definition","text":"<p>This page describes how to create an inventory and a tests catalog.</p>"},{"location":"usage-inventory-catalog/#create-an-inventory-file","title":"Create an inventory file","text":"<p><code>check-devices</code> needs an inventory file to list all devices to tests. This inventory is a YAML file with the folowing keys:</p> <pre><code>anta_inventory:\nhosts:\n- host: 1.1.1.1\nnetworks:\n- network: '1.1.2.0/24'\nranges:\n- start: 1.1.3.10\nend: 1.1.3.21\n</code></pre> <p>In this configuration file, you can use different device definitions:</p> <ul> <li>hosts: is a list of single Arista EOS host to check.</li> <li>networks: is a list of networks where check-devices.py will search for active EOS devices.</li> <li>ranges: is a range of IP addresses where check-devices.py will search for active EOS devices.</li> </ul> <p>Your inventory file can be based on any of these 3 keys and shall start with <code>anta_inventory</code> key.</p> <p>Besides this standard definition, you can also define some tags to target a subset of devices during your tests exeution. it can be useful to only run test about VXLAN on leaf only and skip underlay devices.</p> <pre><code>anta_inventory:\nhosts:\n- host: 1.1.1.1\ntags: ['leaf', 'border']\nnetworks:\n- network: '1.1.2.0/24'\ntags: ['leaf']\nranges:\n- start: 1.1.3.10\nend: 1.1.3.21\ntags: ['spines']\n</code></pre> <p>Tag definition is a list of string you defined according your own setup. If not defined, a default tag (<code>default</code>) is generated during script execution.</p>"},{"location":"usage-inventory-catalog/#test-catalog","title":"Test Catalog","text":"<p>In addition to your inventory file, you also have to define a catalog of tests to execute against all your devices. This catalogue list all your tests and their parameters.</p> <p>Its format is a YAML file and keys are tests functions inherited from the python path. Let\u2019s take an example below:</p>"},{"location":"usage-inventory-catalog/#default-tests-catalog","title":"Default tests catalog","text":"<p>All tests are located under <code>anta.tests</code> module and are categorised per family (one submodule). So to run test for software version, you can do:</p> <pre><code>anta.tests.software:\n- verify_eos_version:\n</code></pre> <p>Information</p> <p>With this approach, it means you can load your own tests collection as described in the next section.</p> <p>It will load the test <code>verify_eos_version</code> located in <code>anta.tests.software</code>. But since this function has parameters, we will create a catalog with the following structure:</p> <pre><code>anta.tests.software:\n- verify_eos_version:\n# List of allowed EOS versions.\nversions:\n- 4.25.4M\n- 4.26.1F\n</code></pre> <p>To get a list of all available tests and their respective parameters, you can read the tests section of this website.</p> <p>The following example gives a very minimal tests catalog you can use in almost any situation</p> <pre><code>---\n# Load anta.tests.software\nanta.tests.software:\n# Verifies the device is running one of the allowed EOS version.\n- verify_eos_version:\n# List of allowed EOS versions.\nversions:\n- 4.25.4M\n- 4.26.1F\n\n# Load anta.tests.system\nanta.tests.system:\n# Verifies the device uptime is higher than a value.\n- verify_uptime:\nminimum: 1\n\n# Load anta.tests.configuration\nanta.tests.configuration:\n# Verifies ZeroTouch is disabled.\n- verify_zerotouch:\n- verify_running_config_diffs:\n</code></pre>"},{"location":"usage-inventory-catalog/#custom-tests-catalog","title":"Custom tests catalog","text":"<p>In case you want to leverage your own tests collection, you can use the following syntax:</p> <pre><code>&lt;your package name&gt;:\n- &lt;your test in your package name&gt;:\n</code></pre> <p>So for instance, it could be:</p> <pre><code>titom73.tests.system:\n- verify_platform:\ntype: ['cEOS-LAB']\n</code></pre> <p>How to create custom tests</p> <p>To create your custom tests, you should refer to this following documentation</p>"},{"location":"usage/","title":"Other scripts","text":""},{"location":"usage/#repository-usage","title":"Repository usage","text":"<p>Once you are done with the installation, you can use the the scripts or the ANTA package.</p>"},{"location":"usage/#how-to-use-the-scripts","title":"How to use the scripts","text":""},{"location":"usage/#how-to-create-an-inventory-from-cvp","title":"How to create an inventory from CVP","text":"<p>The python script create-devices-inventory-from-cvp.py create an inventory text file using CVP.</p> <p>Run these commands to get an inventory with all devices IP address.</p> <pre><code>./create-devices-inventory-from-cvp.py --help\n./create-devices-inventory-from-cvp.py -cvp 192.168.0.5 -u arista -o inventory\ncat inventory/all.yml\n</code></pre> <p>Run these commands to get an inventory with the IP address of the devices under the container <code>Spine</code></p> <pre><code>./create-devices-inventory-from-cvp.py --help\n./create-devices-inventory-from-cvp.py -cvp 192.168.0.5 -u arista -o inventory -c Spine\ncat inventory/Spine.yml\n</code></pre>"},{"location":"usage/#how-to-check-devices-state","title":"How to check devices state","text":"<p>Info</p> <p>Please visit this dedicated section for check-devices.py script</p>"},{"location":"usage/#how-to-collect-commands-output","title":"How to collect commands output","text":"<p>Info</p> <p>Please visit this dedicated section for how to use inventory file.</p> <p>The python script collect-eos-commands.py runs show commands on devices and collects the output:</p> <ul> <li>Update the devices inventory</li> <li>Update the EOS commands list you would like to collect from the devices in text or JSON format</li> <li>Run the python script collect-eos-commands.py</li> <li>The commands output is saved in the output directory</li> </ul> <pre><code>vi inventory.yml\nvi eos-commands.yaml\n./collect-eos-commands.py --help\n./collect-eos-commands.py -i inventory.yml -c eos-commands.yaml -o outdir -u username -p password\nls outdir\n</code></pre>"},{"location":"usage/#how-to-collect-the-scheduled-show-tech-support-files","title":"How to collect the scheduled show tech-support files","text":"<p>Info</p> <p>Please visit this dedicated section for how to use inventory file.</p> <p>The python script collect-sheduled-show-tech.py collects the scheduled show tech-support files:</p> <ul> <li>Update the devices inventory</li> <li>Run the python script collect-sheduled-show-tech.py</li> <li>The files are saved in the output directory</li> </ul> <pre><code>vi inventory.yml\n./collect-sheduled-show-tech.py --help\n./collect-sheduled-show-tech.py -i inventory.yml -u username -o outdir\nls outdir\n</code></pre>"},{"location":"usage/#how-to-clear-counters","title":"How to clear counters","text":"<p>The python script clear-counters.py clears counters:</p> <p>Info</p> <p>Please visit this dedicated section for how to use inventory file.</p> <ul> <li>Update the devices inventory</li> <li>Run the python script clear-counters.py</li> </ul> <pre><code>vi inventory.yml\n./clear-counters.py --help\n./clear-counters.py -i inventory.yml -u username\n</code></pre>"},{"location":"usage/#how-to-clear-the-mac-addresses-which-are-blacklisted-in-evpn","title":"How to clear the MAC addresses which are blacklisted in EVPN","text":"<p>The python script evpn-blacklist-recovery.py clears the MAC addresses which are blacklisted in EVPN:</p> <p>Info</p> <p>Please visit this dedicated section for how to use inventory file.</p> <ul> <li>Update the devices inventory</li> <li>Run the python script evpn-blacklist-recovery.py</li> </ul> <pre><code>vi inventory.yml\n./evpn-blacklist-recovery.py --help\n./evpn-blacklist-recovery.py -i inventory.yml -u username\n</code></pre>"},{"location":"api/inventory/","title":"Inventory module","text":""},{"location":"api/inventory/#anta-inventory-module","title":"ANTA Inventory module","text":"<p>Inventory Abstraction for ANTA framework.</p> <p>Attributes:</p> Name Type Description <code>timeout</code> <code>float</code> <p>Connection to device timeout.</p> <code>INVENTORY_ROOT_KEY</code> <code>str, Optional</code> <p>head of the YAML inventory. Default is anta_inventory</p> <code>EAPI_SESSION_TPL</code> <code>str, Optional</code> <p>Template for eAPI URL builder</p> <code>INVENTORY_OUTPUT_FORMAT</code> <code>List[str], Optional</code> <p>List of supported output format. Default [\u2018native\u2019, \u2018json\u2019]</p> <code>HW_MODEL_KEY</code> <code>str, Optional</code> <p>Name of the key in Arista eAPI JSON provided by device.</p> <p>Examples:</p> <p>Inventory file input</p> <pre><code>print(inventory.yml)\nanta_inventory:\n  hosts:\n    - hosts: 1.1.1.1\n- host: 2.2.2.2\ntags: ['dc1', 'spine', 'pod01']\n  networks:\n    - network: 10.0.0.0/8\n- network: 192.168.0.0/16\ntags: ['dc1', 'spine', 'pod01']\n  ranges:\n    - start: 10.0.0.1\nend: 10.0.0.11\ntags: ['dc1', 'spine', 'pod01']\n</code></pre> <p>Inventory result:</p> <pre><code>test = AntaInventory(\n... inventory_file='examples/inventory.yml',\n... username='ansible',\n... password='ansible',\n... auto_connect=True)\ntest.get_inventory()\n[\n\"InventoryDevice(host=IPv4Address('192.168.0.17')\",\n\"username='ansible'\",\n\"password='ansible'\",\n\"session=&lt;ServerProxy for ansible:ansible@192.168.0.17/command-api&gt;\",\n\"url='https://ansible:ansible@192.168.0.17/command-api'\",\n\"established=True\",\n\"is_online=True\",\n\"hw_model=cEOS-LAB\",\n...\n\"InventoryDevice(host=IPv4Address('192.168.0.2')\",\n\"username='ansible'\",\n\"password='ansible'\",\n\"session=None\",\n\"url='https://ansible:ansible@192.168.0.2/command-api'\",\n\"established=False\"\n\"is_online=False\",\n\"tags\": ['dc1', 'spine', 'pod01'],\n\"hw_model=unset\",\n]\n</code></pre> <p>Raises:</p> Type Description <code>InventoryRootKeyErrors</code> <p>Root key of inventory is missing.</p> <code>InventoryIncorrectSchema</code> <p>Inventory file is not following AntaInventory Schema.</p> <code>InventoryUnknownFormat</code> <p>Output format is not supported.</p> Source code in <code>anta/inventory/__init__.py</code> <pre><code>class AntaInventory:\n\"\"\"\n    Inventory Abstraction for ANTA framework.\n\n    Attributes:\n        timeout (float): Connection to device timeout.\n        INVENTORY_ROOT_KEY (str, Optional): head of the YAML inventory. Default is anta_inventory\n        EAPI_SESSION_TPL (str, Optional): Template for eAPI URL builder\n        INVENTORY_OUTPUT_FORMAT (List[str],Optional): List of supported output format. Default ['native', 'json']\n        HW_MODEL_KEY (str,Optional): Name of the key in Arista eAPI JSON provided by device.\n\n    Examples:\n\n        Inventory file input\n\n            print(inventory.yml)\n            anta_inventory:\n              hosts:\n                - hosts: 1.1.1.1\n                - host: 2.2.2.2\n                  tags: ['dc1', 'spine', 'pod01']\n              networks:\n                - network: 10.0.0.0/8\n                - network: 192.168.0.0/16\n                  tags: ['dc1', 'spine', 'pod01']\n              ranges:\n                - start: 10.0.0.1\n                  end: 10.0.0.11\n                  tags: ['dc1', 'spine', 'pod01']\n\n        Inventory result:\n\n            test = AntaInventory(\n                ... inventory_file='examples/inventory.yml',\n                ... username='ansible',\n                ... password='ansible',\n                ... auto_connect=True)\n            test.get_inventory()\n            [\n                    \"InventoryDevice(host=IPv4Address('192.168.0.17')\",\n                    \"username='ansible'\",\n                    \"password='ansible'\",\n                    \"session=&lt;ServerProxy for ansible:ansible@192.168.0.17/command-api&gt;\",\n                    \"url='https://ansible:ansible@192.168.0.17/command-api'\",\n                    \"established=True\",\n                    \"is_online=True\",\n                    \"hw_model=cEOS-LAB\",\n                 ...\n                    \"InventoryDevice(host=IPv4Address('192.168.0.2')\",\n                    \"username='ansible'\",\n                    \"password='ansible'\",\n                    \"session=None\",\n                    \"url='https://ansible:ansible@192.168.0.2/command-api'\",\n                    \"established=False\"\n                    \"is_online=False\",\n                    \"tags\": ['dc1', 'spine', 'pod01'],\n                    \"hw_model=unset\",\n                ]\n\n    Raises:\n        InventoryRootKeyErrors: Root key of inventory is missing.\n        InventoryIncorrectSchema: Inventory file is not following AntaInventory Schema.\n        InventoryUnknownFormat: Output format is not supported.\n\n    \"\"\"\n\n    # Root key of inventory part of the inventory file\n    INVENTORY_ROOT_KEY = \"anta_inventory\"\n    # Supported Output format\n    INVENTORY_OUTPUT_FORMAT = [\"native\", \"json\"]\n    # HW model definition in show version\n    HW_MODEL_KEY = \"modelName\"\n\n    # pylint: disable=R0913\n    def __init__(\n        self,\n        inventory_file: str,\n        username: str,\n        password: str,\n        enable_password: Optional[str] = None,\n        timeout: Optional[float] = None,\n        filter_hosts: Optional[List[str]] = None,\n    ) -&gt; None:\n\"\"\"Class constructor.\n\n        Args:\n            inventory_file (str): Path to inventory YAML file where user has described his inputs\n            username (str): Username to use to connect to devices\n            password (str): Password to use to connect to devices\n            timeout (float, optional): timeout in seconds for every API call.\n            filter_hosts (str, optional): create inventory only with matching host name in this list.\n        \"\"\"\n        self._username = username\n        self._password = password\n        self._enable_password = enable_password\n        self.timeout = timeout\n        self._inventory = InventoryDevices()\n\n        with open(inventory_file, \"r\", encoding=\"utf8\") as fd:\n            data = yaml.load(fd, Loader=SafeLoader)\n\n        # Load data using Pydantic\n        try:\n            self._read_inventory = AntaInventoryInput(**data[self.INVENTORY_ROOT_KEY])\n        except KeyError as exc:\n            logger.error(f\"Inventory root key is missing: {self.INVENTORY_ROOT_KEY}\")\n            raise InventoryRootKeyErrors(\n                f\"Inventory root key ({self.INVENTORY_ROOT_KEY}) is not defined in your inventory\"\n            ) from exc\n        except ValidationError as exc:\n            logger.error(\"Inventory data are not compliant with inventory models\")\n            raise InventoryIncorrectSchema(\"Inventory is not following schema\") from exc\n\n        # Read data from input\n        if self._read_inventory.dict()[\"hosts\"] is not None:\n            self._inventory_read_hosts()\n        if self._read_inventory.dict()[\"networks\"] is not None:\n            self._inventory_read_networks()\n        if self._read_inventory.dict()[\"ranges\"] is not None:\n            self._inventory_read_ranges()\n\n        if filter_hosts:\n            for device in self._inventory:\n                if device.url.host not in filter_hosts:\n                    del device\n\n    ###########################################################################\n    # Boolean methods\n    ###########################################################################\n\n    def _is_ip_exist(self, ip: str) -&gt; bool:  # TODO mtache: unused, remove this ?\n\"\"\"Check if an IP is part of the current inventory.\n\n        Args:\n            ip (str): IP address to search in our inventory\n\n        Returns:\n            bool: True if device is in our inventory, False if not\n        \"\"\"\n        logger.debug(f\"Checking if device {ip} is in our inventory\")\n        return (\n            len([str(dev.host) for dev in self._inventory if str(ip) == str(dev.host)])\n            == 1\n        )\n\n    ###########################################################################\n    # Internal methods\n    ###########################################################################\n\n    async def _read_device_hw(self, device: InventoryDevice) -&gt; None:\n\"\"\"\n        _read_device_hw Get HW model name from show version and update the hw_model attribute.\n\n        Args:\n            device (InventoryDevice): Device to update\n        \"\"\"\n        logger.debug(f\"Reading HW information for {device.name}\")\n        try:\n            response = await device.session.cli(command=\"show version\")\n        except EapiCommandError as e:\n            logger.warning(\n                f\"Cannot get HW information from device {device.name}: {e.errmsg}\"\n            )\n        except (HTTPError, ConnectError) as e:\n            logger.warning(\n                f\"Cannot get HW information from device {device.name}: {type(e).__name__}{'' if not str(e) else f' ({str(e)})'}\"\n            )\n        else:\n            if self.HW_MODEL_KEY in response:\n                device.hw_model = response[self.HW_MODEL_KEY]\n            else:\n                logger.warning(\n                    f\"Cannot get HW information from device {device.name}: cannot parse 'show version'\"\n                )\n\n    async def _refresh_device_fact(self, device: InventoryDevice) -&gt; None:\n\"\"\"\n        _get_from_device Update the is_online and established flags for InventoryDevice.\n\n        It updates following keys:\n        - is_online: When a device IP is reachable and a port can be open\n        - established: When a CLI command in EXEC mode succeed using eAPI\n        - hw_model: The hardware model string of the device\n\n        Args:\n            device (InventoryDevice): Device to check using InventoryDevice structure.\n\n        Returns:\n            InventoryDevice: Updated structure with devices information\n        \"\"\"\n        logger.debug(f\"Refreshing device {device.name}\")\n        device.is_online = await device.session.check_connection()\n        if device.is_online:\n            await self._read_device_hw(device=device)\n        else:\n            logger.warning(\n                f\"Could not connect to device {device.name}: cannot open eAPI port\"\n            )\n        device.established = bool(device.is_online and device.hw_model)\n\n    def _add_device_to_inventory(\n        self,\n        host: str,\n        port: Optional[int] = None,\n        name: Optional[str] = None,\n        tags: Optional[List[str]] = None,\n    ) -&gt; None:\n\"\"\"Add a InventoryDevice to final inventory.\n\n        Create InventoryDevice and append to existing inventory\n\n        Args:\n            host (str): IP address or hostname of the device\n            port (int): eAPI port of the device\n            name (str): Optional name of the device\n        \"\"\"\n        kwargs: Dict[str, Any] = {\n            \"host\": host,\n            \"username\": self._username,\n            \"password\": self._password,\n        }\n        if name:\n            kwargs[\"name\"] = name\n        if port:\n            kwargs[\"port\"] = port\n        if self._enable_password:\n            kwargs[\"enable_password\"] = self._enable_password\n        if tags:\n            kwargs[\"tags\"] = tags\n        if self.timeout:\n            kwargs[\"timeout\"] = self.timeout\n        device = InventoryDevice(**kwargs)\n        self._inventory.append(device)\n\n    def _inventory_read_hosts(self) -&gt; None:\n\"\"\"Read input data from hosts section and create inventory structure.\n\n        Build InventoryDevice structure for all hosts under hosts section\n        \"\"\"\n        assert self._read_inventory.hosts is not None\n        for host in self._read_inventory.hosts:\n            self._add_device_to_inventory(\n                host.host, host.port, host.name, tags=host.tags\n            )\n\n    def _inventory_read_networks(self) -&gt; None:\n\"\"\"Read input data from networks section and create inventory structure.\n\n        Build InventoryDevice structure for all IPs available in each declared subnet\n        \"\"\"\n        assert self._read_inventory.networks is not None\n        for network in self._read_inventory.networks:\n            for host_ip in IPNetwork(str(network.network)):\n                self._add_device_to_inventory(host_ip, tags=network.tags)\n\n    def _inventory_read_ranges(self) -&gt; None:\n\"\"\"Read input data from ranges section and create inventory structure.\n\n        Build InventoryDevice structure for all IPs available in each declared range\n        \"\"\"\n        assert self._read_inventory.ranges is not None\n        for range_def in self._read_inventory.ranges:\n            range_increment = IPAddress(str(range_def.start))\n            range_stop = IPAddress(str(range_def.end))\n            while range_increment &lt;= range_stop:\n                self._add_device_to_inventory(str(range_increment), tags=range_def.tags)\n                range_increment += 1\n\n    ###########################################################################\n    # Public methods\n    ###########################################################################\n\n    ###########################################################################\n    # GET methods\n    ###########################################################################\n\n    def get_inventory(\n        self, established_only: bool = False, tags: Optional[List[str]] = None\n    ) -&gt; InventoryDevices:\n\"\"\"\n        get_inventory Returns a new filtered inventory.\n\n        Args:\n            established_only (bool, optional): Whether or not including non-established devices in the Inventory.\n                                               Default False.\n            tags (List[str], optional): List of tags to use to filter devices. Default is [default].\n\n        Returns:\n            InventoryDevices: An inventory with concerned devices\n        \"\"\"\n        if tags is None:\n            tags = [DEFAULT_TAG]\n\n        inventory_filtered_tags = InventoryDevices()\n        for device in self._inventory:\n            if tags and any(tag in tags for tag in device.tags):\n                inventory_filtered_tags.append(device)\n        if not established_only:\n            return inventory_filtered_tags\n\n        inventory_final = InventoryDevices()\n        for device in inventory_filtered_tags:\n            if device.established:\n                inventory_final.append(device)\n        return inventory_final\n\n    ###########################################################################\n    # MISC methods\n    ###########################################################################\n\n    async def connect_inventory(self) -&gt; None:\n\"\"\"connect_inventory Helper to prepare inventory with network data.\"\"\"\n        logger.debug(\"Refreshing facts for current inventory\")\n        results = await asyncio.gather(\n            *(self._refresh_device_fact(device) for device in self._inventory),\n            return_exceptions=True,\n        )\n        for r in results:\n            if isinstance(r, Exception):\n                logger.error(\n                    f\"Error when initiating inventory: {r.__class__.__name__}{'' if not str(r) else f' ({str(r)})'}\"\n                )\n</code></pre>"},{"location":"api/inventory/#anta.inventory.AntaInventory.__init__","title":"<code>__init__(inventory_file, username, password, enable_password=None, timeout=None, filter_hosts=None)</code>","text":"<p>Class constructor.</p> <p>Parameters:</p> Name Type Description Default <code>inventory_file</code> <code>str</code> <p>Path to inventory YAML file where user has described his inputs</p> required <code>username</code> <code>str</code> <p>Username to use to connect to devices</p> required <code>password</code> <code>str</code> <p>Password to use to connect to devices</p> required <code>timeout</code> <code>float</code> <p>timeout in seconds for every API call.</p> <code>None</code> <code>filter_hosts</code> <code>str</code> <p>create inventory only with matching host name in this list.</p> <code>None</code> Source code in <code>anta/inventory/__init__.py</code> <pre><code>def __init__(\n    self,\n    inventory_file: str,\n    username: str,\n    password: str,\n    enable_password: Optional[str] = None,\n    timeout: Optional[float] = None,\n    filter_hosts: Optional[List[str]] = None,\n) -&gt; None:\n\"\"\"Class constructor.\n\n    Args:\n        inventory_file (str): Path to inventory YAML file where user has described his inputs\n        username (str): Username to use to connect to devices\n        password (str): Password to use to connect to devices\n        timeout (float, optional): timeout in seconds for every API call.\n        filter_hosts (str, optional): create inventory only with matching host name in this list.\n    \"\"\"\n    self._username = username\n    self._password = password\n    self._enable_password = enable_password\n    self.timeout = timeout\n    self._inventory = InventoryDevices()\n\n    with open(inventory_file, \"r\", encoding=\"utf8\") as fd:\n        data = yaml.load(fd, Loader=SafeLoader)\n\n    # Load data using Pydantic\n    try:\n        self._read_inventory = AntaInventoryInput(**data[self.INVENTORY_ROOT_KEY])\n    except KeyError as exc:\n        logger.error(f\"Inventory root key is missing: {self.INVENTORY_ROOT_KEY}\")\n        raise InventoryRootKeyErrors(\n            f\"Inventory root key ({self.INVENTORY_ROOT_KEY}) is not defined in your inventory\"\n        ) from exc\n    except ValidationError as exc:\n        logger.error(\"Inventory data are not compliant with inventory models\")\n        raise InventoryIncorrectSchema(\"Inventory is not following schema\") from exc\n\n    # Read data from input\n    if self._read_inventory.dict()[\"hosts\"] is not None:\n        self._inventory_read_hosts()\n    if self._read_inventory.dict()[\"networks\"] is not None:\n        self._inventory_read_networks()\n    if self._read_inventory.dict()[\"ranges\"] is not None:\n        self._inventory_read_ranges()\n\n    if filter_hosts:\n        for device in self._inventory:\n            if device.url.host not in filter_hosts:\n                del device\n</code></pre>"},{"location":"api/inventory/#anta.inventory.AntaInventory.connect_inventory","title":"<code>connect_inventory()</code>  <code>async</code>","text":"<p>connect_inventory Helper to prepare inventory with network data.</p> Source code in <code>anta/inventory/__init__.py</code> <pre><code>async def connect_inventory(self) -&gt; None:\n\"\"\"connect_inventory Helper to prepare inventory with network data.\"\"\"\n    logger.debug(\"Refreshing facts for current inventory\")\n    results = await asyncio.gather(\n        *(self._refresh_device_fact(device) for device in self._inventory),\n        return_exceptions=True,\n    )\n    for r in results:\n        if isinstance(r, Exception):\n            logger.error(\n                f\"Error when initiating inventory: {r.__class__.__name__}{'' if not str(r) else f' ({str(r)})'}\"\n            )\n</code></pre>"},{"location":"api/inventory/#anta.inventory.AntaInventory.get_inventory","title":"<code>get_inventory(established_only=False, tags=None)</code>","text":"<p>get_inventory Returns a new filtered inventory.</p> <p>Parameters:</p> Name Type Description Default <code>established_only</code> <code>bool</code> <p>Whether or not including non-established devices in the Inventory.                                Default False.</p> <code>False</code> <code>tags</code> <code>List[str]</code> <p>List of tags to use to filter devices. Default is [default].</p> <code>None</code> <p>Returns:</p> Name Type Description <code>InventoryDevices</code> <code>InventoryDevices</code> <p>An inventory with concerned devices</p> Source code in <code>anta/inventory/__init__.py</code> <pre><code>def get_inventory(\n    self, established_only: bool = False, tags: Optional[List[str]] = None\n) -&gt; InventoryDevices:\n\"\"\"\n    get_inventory Returns a new filtered inventory.\n\n    Args:\n        established_only (bool, optional): Whether or not including non-established devices in the Inventory.\n                                           Default False.\n        tags (List[str], optional): List of tags to use to filter devices. Default is [default].\n\n    Returns:\n        InventoryDevices: An inventory with concerned devices\n    \"\"\"\n    if tags is None:\n        tags = [DEFAULT_TAG]\n\n    inventory_filtered_tags = InventoryDevices()\n    for device in self._inventory:\n        if tags and any(tag in tags for tag in device.tags):\n            inventory_filtered_tags.append(device)\n    if not established_only:\n        return inventory_filtered_tags\n\n    inventory_final = InventoryDevices()\n    for device in inventory_filtered_tags:\n        if device.established:\n            inventory_final.append(device)\n    return inventory_final\n</code></pre>"},{"location":"api/inventory/#exceptions","title":"Exceptions","text":"<p>Manage Exception in Inventory module.</p>"},{"location":"api/inventory/#anta.inventory.exceptions.InventoryIncorrectSchema","title":"<code>InventoryIncorrectSchema</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Error when user data does not follow ANTA schema.</p> Source code in <code>anta/inventory/exceptions.py</code> <pre><code>class InventoryIncorrectSchema(Exception):\n\"\"\"Error when user data does not follow ANTA schema.\"\"\"\n</code></pre>"},{"location":"api/inventory/#anta.inventory.exceptions.InventoryRootKeyErrors","title":"<code>InventoryRootKeyErrors</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Error raised when inventory root key is not found.</p> Source code in <code>anta/inventory/exceptions.py</code> <pre><code>class InventoryRootKeyErrors(Exception):\n\"\"\"Error raised when inventory root key is not found.\"\"\"\n</code></pre>"},{"location":"api/inventory.models.input/","title":"User Inventory data model","text":""},{"location":"api/inventory.models.input/#data-models-for-antainventory","title":"Data models for anta.inventory","text":"<p>         Bases: <code>BaseModel</code></p> <p>User\u2019s inventory model.</p> <p>Attributes:</p> Name Type Description <code>networks</code> <code>List[AntaInventoryNetwork], Optional</code> <p>List of AntaInventoryNetwork objects for networks.</p> <code>hosts</code> <code>List[AntaInventoryHost], Optional</code> <p>List of AntaInventoryHost objects for hosts.</p> <code>range</code> <code>List[AntaInventoryRange], Optional</code> <p>List of AntaInventoryRange objects for ranges.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>class AntaInventoryInput(BaseModel):\n\"\"\"\n    User's inventory model.\n\n    Attributes:\n        networks (List[AntaInventoryNetwork],Optional): List of AntaInventoryNetwork objects for networks.\n        hosts (List[AntaInventoryHost],Optional): List of AntaInventoryHost objects for hosts.\n        range (List[AntaInventoryRange],Optional): List of AntaInventoryRange objects for ranges.\n    \"\"\"\n\n    networks: Optional[List[AntaInventoryNetwork]]\n    hosts: Optional[List[AntaInventoryHost]]\n    ranges: Optional[List[AntaInventoryRange]]\n</code></pre>"},{"location":"api/inventory.models.input/#user-inventory-components","title":"User inventory components","text":"<p>         Bases: <code>BaseModel</code></p> <p>Host definition for user\u2019s inventory.</p> <p>Attributes:</p> Name Type Description <code>host</code> <code>IPvAnyAddress</code> <p>IPv4 or IPv6 address of the device</p> <code>tags</code> <code>List[str]</code> <p>List of attached tags read from inventory file.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>class AntaInventoryHost(BaseModel):\n\"\"\"\n    Host definition for user's inventory.\n\n    Attributes:\n        host (IPvAnyAddress): IPv4 or IPv6 address of the device\n        tags (List[str]): List of attached tags read from inventory file.\n    \"\"\"\n\n    name: Optional[str]\n    host: Union[constr(regex=RFC_1123_REGEX), IPvAnyAddress]  # type: ignore\n    port: Optional[conint(gt=1, lt=65535)]  # type: ignore\n    tags: List[str] = [DEFAULT_TAG]\n</code></pre> <p>         Bases: <code>BaseModel</code></p> <p>Network definition for user\u2019s inventory.</p> <p>Attributes:</p> Name Type Description <code>network</code> <code>IPvAnyNetwork</code> <p>Subnet to use for testing.</p> <code>tags</code> <code>List[str]</code> <p>List of attached tags read from inventory file.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>class AntaInventoryNetwork(BaseModel):\n\"\"\"\n    Network definition for user's inventory.\n\n    Attributes:\n        network (IPvAnyNetwork): Subnet to use for testing.\n        tags (List[str]): List of attached tags read from inventory file.\n    \"\"\"\n\n    network: IPvAnyNetwork\n    tags: List[str] = [DEFAULT_TAG]\n</code></pre> <p>         Bases: <code>BaseModel</code></p> <p>IP Range definition for user\u2019s inventory.</p> <p>Attributes:</p> Name Type Description <code>start</code> <code>IPvAnyAddress</code> <p>IPv4 or IPv6 address for the begining of the range.</p> <code>stop</code> <code>IPvAnyAddress</code> <p>IPv4 or IPv6 address for the end of the range.</p> <code>tags</code> <code>List[str]</code> <p>List of attached tags read from inventory file.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>class AntaInventoryRange(BaseModel):\n\"\"\"\n    IP Range definition for user's inventory.\n\n    Attributes:\n        start (IPvAnyAddress): IPv4 or IPv6 address for the begining of the range.\n        stop (IPvAnyAddress): IPv4 or IPv6 address for the end of the range.\n        tags (List[str]): List of attached tags read from inventory file.\n    \"\"\"\n\n    start: IPvAnyAddress\n    end: IPvAnyAddress\n    tags: List[str] = [DEFAULT_TAG]\n</code></pre>"},{"location":"api/inventory.models/","title":"Generated Inventory data model","text":""},{"location":"api/inventory.models/#inventory-entry","title":"Inventory Entry","text":"<p>         Bases: <code>BaseModel</code></p> <p>Inventory model exposed by Inventory class.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Device name</p> <code>username</code> <code>str</code> <p>Username to use for connection.</p> <code>password</code> <code>password</code> <p>Password to use for connection.</p> <code>enable_password</code> <code>Optional[str]</code> <p>enable_password to use on the device, required for some tests</p> <code>session</code> <code>Any</code> <p>JSONRPC session.</p> <code>established</code> <code>bool</code> <p>Flag to mark if connection is established (True) or not (False). Default: False.</p> <code>is_online</code> <code>bool</code> <p>Flag to mark if host is alive (True) or not (False). Default: False.</p> <code>hw_model</code> <code>str</code> <p>HW name gathered during device discovery.</p> <code>url</code> <code>str</code> <p>eAPI URL to use to build session.</p> <code>tags</code> <code>List[str]</code> <p>List of attached tags read from inventory file.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>class InventoryDevice(BaseModel):\n\"\"\"\n    Inventory model exposed by Inventory class.\n\n    Attributes:\n        name (str): Device name\n        username (str): Username to use for connection.\n        password (password): Password to use for connection.\n        enable_password (Optional[str]): enable_password to use on the device, required for some tests\n        session (Any): JSONRPC session.\n        established (bool): Flag to mark if connection is established (True) or not (False). Default: False.\n        is_online (bool): Flag to mark if host is alive (True) or not (False). Default: False.\n        hw_model (str): HW name gathered during device discovery.\n        url (str): eAPI URL to use to build session.\n        tags (List[str]): List of attached tags read from inventory file.\n    \"\"\"\n\n    class Config:  # pylint: disable=too-few-public-methods\n\"\"\" Pydantic model configuration \"\"\"\n        arbitrary_types_allowed = True\n\n    name: str\n    host: Union[constr(regex=RFC_1123_REGEX), IPvAnyAddress]  # type: ignore[valid-type]\n    username: str\n    password: str\n    port: conint(gt=1, lt=65535)  # type: ignore[valid-type]\n    enable_password: Optional[str]\n    session: Device\n    established = False\n    is_online = False\n    hw_model: str = DEFAULT_HW_MODEL\n    tags: List[str] = [DEFAULT_TAG]\n    timeout: float = 10.0\n\n    @root_validator(pre=True)\n    def build_device(cls: Type[Any], values: Dict[str, Any]) -&gt; Dict[str, Any]:\n\"\"\" Build the device session object \"\"\"\n        if not values.get('host'):\n            values['host'] = 'localhost'\n        if not values.get('port'):\n            values['port'] = '8080' if values['host'] == 'localhost' else '443'\n        if values.get('session') is None:\n            proto = 'http' if values['port'] in ['80', '8080'] else 'https'\n            values['session'] = Device(host=values['host'], port=values['port'],\n                                       username=values.get('username'), password=values.get('password'),\n                                       proto=proto, timeout=values.get('timeout'))\n        if values.get('name') is None:\n            values['name'] = f\"{values['host']}:{values['port']}\"\n        return values\n\n    def __eq__(self, other: BaseModel) -&gt; bool:\n\"\"\"\n            Two InventoryDevice objects are equal if the hostname and the port are the same.\n            This covers the use case of port forwarding when the host is localhost and the devices have different ports.\n        \"\"\"\n        return self.session.host == other.session.host and self.session.port == other.session.port\n\n    def assert_enable_password_is_not_none(self, test_name: Optional[str] = None) -&gt; None:\n\"\"\"\n        raise ValueError is enable_password is None\n        \"\"\"\n        if not self.enable_password:\n            if test_name:\n                message = f\"{test_name} requires `enable_password` to be set\"\n            else:\n                message = \"`enable_password` is not set\"\n            raise ValueError(message)\n</code></pre>"},{"location":"api/inventory.models/#anta.inventory.models.InventoryDevice.Config","title":"<code>Config</code>","text":"<p>Pydantic model configuration</p> Source code in <code>anta/inventory/models.py</code> <pre><code>class Config:  # pylint: disable=too-few-public-methods\n\"\"\" Pydantic model configuration \"\"\"\n    arbitrary_types_allowed = True\n</code></pre>"},{"location":"api/inventory.models/#anta.inventory.models.InventoryDevice.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Two InventoryDevice objects are equal if the hostname and the port are the same. This covers the use case of port forwarding when the host is localhost and the devices have different ports.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>def __eq__(self, other: BaseModel) -&gt; bool:\n\"\"\"\n        Two InventoryDevice objects are equal if the hostname and the port are the same.\n        This covers the use case of port forwarding when the host is localhost and the devices have different ports.\n    \"\"\"\n    return self.session.host == other.session.host and self.session.port == other.session.port\n</code></pre>"},{"location":"api/inventory.models/#anta.inventory.models.InventoryDevice.assert_enable_password_is_not_none","title":"<code>assert_enable_password_is_not_none(test_name=None)</code>","text":"<p>raise ValueError is enable_password is None</p> Source code in <code>anta/inventory/models.py</code> <pre><code>def assert_enable_password_is_not_none(self, test_name: Optional[str] = None) -&gt; None:\n\"\"\"\n    raise ValueError is enable_password is None\n    \"\"\"\n    if not self.enable_password:\n        if test_name:\n            message = f\"{test_name} requires `enable_password` to be set\"\n        else:\n            message = \"`enable_password` is not set\"\n        raise ValueError(message)\n</code></pre>"},{"location":"api/inventory.models/#anta.inventory.models.InventoryDevice.build_device","title":"<code>build_device(values)</code>","text":"<p>Build the device session object</p> Source code in <code>anta/inventory/models.py</code> <pre><code>@root_validator(pre=True)\ndef build_device(cls: Type[Any], values: Dict[str, Any]) -&gt; Dict[str, Any]:\n\"\"\" Build the device session object \"\"\"\n    if not values.get('host'):\n        values['host'] = 'localhost'\n    if not values.get('port'):\n        values['port'] = '8080' if values['host'] == 'localhost' else '443'\n    if values.get('session') is None:\n        proto = 'http' if values['port'] in ['80', '8080'] else 'https'\n        values['session'] = Device(host=values['host'], port=values['port'],\n                                   username=values.get('username'), password=values.get('password'),\n                                   proto=proto, timeout=values.get('timeout'))\n    if values.get('name') is None:\n        values['name'] = f\"{values['host']}:{values['port']}\"\n    return values\n</code></pre>"},{"location":"api/inventory.models/#inventory","title":"Inventory","text":"<p>         Bases: <code>BaseModel</code></p> <p>Inventory model to list all InventoryDevice entries.</p> <p>Attributes:</p> Name Type Description <code>__root__(List[InventoryDevice])</code> <p>A list of InventoryDevice objects.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>class InventoryDevices(BaseModel):\n\"\"\"\n    Inventory model to list all InventoryDevice entries.\n\n    Attributes:\n        __root__(List[InventoryDevice]): A list of InventoryDevice objects.\n    \"\"\"\n    # pylint: disable=R0801\n\n    __root__: List[InventoryDevice] = []\n\n    def append(self, value: InventoryDevice) -&gt; None:\n\"\"\"Add support for append method.\"\"\"\n        self.__root__.append(value)\n\n    def __iter__(self) -&gt; Iterator[InventoryDevice]:\n\"\"\"Use custom iter method.\"\"\"\n        return iter(self.__root__)\n\n    def __getitem__(self, item: int) -&gt; InventoryDevice:\n\"\"\"Use custom getitem method.\"\"\"\n        return self.__root__[item]\n\n    def __len__(self) -&gt; int:\n\"\"\"Support for length of __root__\"\"\"\n        return len(self.__root__)\n\n    def json(self) -&gt; str:\n\"\"\"Returns a JSON representation of the devices\"\"\"\n        return super().json(exclude={'__root__': {'__all__': {'session'}}})\n</code></pre>"},{"location":"api/inventory.models/#anta.inventory.models.InventoryDevices.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Use custom getitem method.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>def __getitem__(self, item: int) -&gt; InventoryDevice:\n\"\"\"Use custom getitem method.\"\"\"\n    return self.__root__[item]\n</code></pre>"},{"location":"api/inventory.models/#anta.inventory.models.InventoryDevices.__iter__","title":"<code>__iter__()</code>","text":"<p>Use custom iter method.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>def __iter__(self) -&gt; Iterator[InventoryDevice]:\n\"\"\"Use custom iter method.\"\"\"\n    return iter(self.__root__)\n</code></pre>"},{"location":"api/inventory.models/#anta.inventory.models.InventoryDevices.__len__","title":"<code>__len__()</code>","text":"<p>Support for length of root</p> Source code in <code>anta/inventory/models.py</code> <pre><code>def __len__(self) -&gt; int:\n\"\"\"Support for length of __root__\"\"\"\n    return len(self.__root__)\n</code></pre>"},{"location":"api/inventory.models/#anta.inventory.models.InventoryDevices.append","title":"<code>append(value)</code>","text":"<p>Add support for append method.</p> Source code in <code>anta/inventory/models.py</code> <pre><code>def append(self, value: InventoryDevice) -&gt; None:\n\"\"\"Add support for append method.\"\"\"\n    self.__root__.append(value)\n</code></pre>"},{"location":"api/inventory.models/#anta.inventory.models.InventoryDevices.json","title":"<code>json()</code>","text":"<p>Returns a JSON representation of the devices</p> Source code in <code>anta/inventory/models.py</code> <pre><code>def json(self) -&gt; str:\n\"\"\"Returns a JSON representation of the devices\"\"\"\n    return super().json(exclude={'__root__': {'__all__': {'session'}}})\n</code></pre>"},{"location":"api/result_manager/","title":"Result Manager module","text":""},{"location":"api/result_manager/#anta-resultmanager-module","title":"ANTA ResultManager module","text":"<p>Helper to manage Test Results and generate reports.</p> <p>Examples:</p> <p>Create Inventory:</p> <pre><code>inventory_anta = AntaInventory(\n    inventory_file='examples/inventory.yml',\n    username='ansible',\n    password='ansible',\n    timeout=0.5,\n    auto_connect=True\n)\n</code></pre> <p>Create Result Manager:</p> <pre><code>manager = ResultManager()\n</code></pre> <p>Run tests for all connected devices:</p> <pre><code>for device in inventory_anta.get_inventory():\n    manager.add_test_result(\nverify_eos_version(\ndevice=device, versions=['4.28.0F']\n        )\n)\nmanager.add_test_result(\nverify_uptime(\ndevice=device, minimum=1\n)\n)\n</code></pre> <p>Print result in native format:</p> <pre><code>manager.get_results()\n[\n    TestResult(\n        host=IPv4Address('192.168.0.10'),\n        test='verify_eos_version',\n        result='failure',\n        message=\"device is running version 4.27.3F-26379303.4273F (engineering build) and test expect ['4.28.0F']\"\n    ),\n    TestResult(\n        host=IPv4Address('192.168.0.10'),\n        test='verify_eos_version',\n        result='success',\n        message=None\n    ),\n]\n</code></pre> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>class ResultManager:\n\"\"\"\n    Helper to manage Test Results and generate reports.\n\n    Examples:\n\n        Create Inventory:\n\n            inventory_anta = AntaInventory(\n                inventory_file='examples/inventory.yml',\n                username='ansible',\n                password='ansible',\n                timeout=0.5,\n                auto_connect=True\n            )\n\n        Create Result Manager:\n\n            manager = ResultManager()\n\n        Run tests for all connected devices:\n\n            for device in inventory_anta.get_inventory():\n                manager.add_test_result(\n                    verify_eos_version(\n                        device=device, versions=['4.28.0F']\n                    )\n                )\n                manager.add_test_result(\n                    verify_uptime(\n                        device=device, minimum=1\n                    )\n                )\n\n        Print result in native format:\n\n            manager.get_results()\n            [\n                TestResult(\n                    host=IPv4Address('192.168.0.10'),\n                    test='verify_eos_version',\n                    result='failure',\n                    message=\"device is running version 4.27.3F-26379303.4273F (engineering build) and test expect ['4.28.0F']\"\n                ),\n                TestResult(\n                    host=IPv4Address('192.168.0.10'),\n                    test='verify_eos_version',\n                    result='success',\n                    message=None\n                ),\n            ]\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n\"\"\" Class constructor.\"\"\"\n        logger.debug('Instantiate result-manager')\n        self._result_entries = ListResult()\n\n    def __len__(self) -&gt; int:\n\"\"\"\n        Implement __len__ method to count number of results.\n        \"\"\"\n        return len(self._result_entries)\n\n    def add_test_result(self, entry: TestResult) -&gt; None:\n\"\"\"Add a result to the list\n\n        Args:\n            entry (TestResult): TestResult data to add to the report\n        \"\"\"\n        logger.info(f'add new test result to manager: {entry}')\n        self._result_entries.append(entry)\n\n    def add_test_results(self, entries: List[TestResult]) -&gt; None:\n\"\"\"Add a list of results to the list\n\n        Args:\n            entries (List[TestResult]): list of TestResult data to add to the report\n        \"\"\"\n        logger.info(f'add new list of results to manager: {[str(r) for r in entries]}')\n        self._result_entries.extend(entries)\n\n    def get_results(self, output_format: str = \"native\") -&gt; Any:\n\"\"\"\n        Expose list of all test results in different format\n\n        Support multiple format:\n          - native: ListResults format\n          - list: a list of TestResult\n          - json: a native JSON format\n\n        Args:\n            output_format (str, optional): format selector. Can be either native/list/json. Defaults to 'native'.\n\n        Returns:\n            any: List of results.\n        \"\"\"\n        logger.info(f'retrieve list of result using output_format {output_format}')\n        if output_format == 'list':\n            return list(self._result_entries)\n\n        if output_format == \"json\":\n            return json.dumps(pydantic_to_dict(self._result_entries), indent=4)\n\n        # Default return for native format.\n        return self._result_entries\n\n    def get_result_by_test(self, test_name: str, output_format: str = \"native\") -&gt; Any:\n\"\"\"\n        Get list of test result for a given test.\n\n        Args:\n            test_name (str): Test name to use to filter results\n            output_format (str, optional): format selector. Can be either native/list. Defaults to 'native'.\n\n        Returns:\n            list[TestResult]: List of results related to the test.\n        \"\"\"\n        logger.info(\n            f'retrieve list of result using output_format {output_format} for test {test_name}')\n        if output_format == \"list\":\n            return [\n                result\n                for result in self._result_entries\n                if str(result.test) == test_name\n            ]\n\n        result_manager_filtered = ListResult()\n        for result in self._result_entries:\n            if result.test == test_name:\n                result_manager_filtered.append(result)\n        return result_manager_filtered\n\n    def get_result_by_host(self, host_ip: str, output_format: str = \"native\") -&gt; Any:\n\"\"\"\n        Get list of test result for a given host.\n\n        Args:\n            host_ip (str): IP Address of the host to use to filter results.\n            output_format (str, optional): format selector. Can be either native/list. Defaults to 'native'.\n\n        Returns:\n            Any: List of results related to the host.\n        \"\"\"\n        logger.info(\n            f'retrieve list of result using output_format {output_format} for host {host_ip}')\n        if output_format == \"list\":\n            return [\n                result for result in self._result_entries if str(result.name) == host_ip\n            ]\n\n        result_manager_filtered = ListResult()\n        for result in self._result_entries:\n            if str(result.name) == host_ip:\n                result_manager_filtered.append(result)\n        return result_manager_filtered\n\n    def get_testcases(self) -&gt; List[str]:\n\"\"\"\n        Get list of name of all test cases in current manager.\n\n        Returns:\n            List[str]: List of names for all tests.\n        \"\"\"\n        logger.info('build list of testcases registered in result-manager')\n        result_list = []\n        for testcase in self._result_entries:\n            if str(testcase.test) not in result_list:\n                result_list.append(str(testcase.test))\n        logger.debug(f'list of tests name: {result_list}')\n        return result_list\n\n    def get_hosts(self) -&gt; List[str]:\n\"\"\"\n        Get list of IP addresses in current manager.\n\n        Returns:\n            List[str]: List of IP addresses.\n        \"\"\"\n        logger.info('build list of host ip registered in result-manager')\n        result_list = []\n        for testcase in self._result_entries:\n            if str(testcase.name) not in result_list:\n                result_list.append(str(testcase.name))\n        logger.debug(f'list of tests name: {result_list}')\n        return result_list\n</code></pre>"},{"location":"api/result_manager/#anta.result_manager.ResultManager.__init__","title":"<code>__init__()</code>","text":"<p>Class constructor.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def __init__(self) -&gt; None:\n\"\"\" Class constructor.\"\"\"\n    logger.debug('Instantiate result-manager')\n    self._result_entries = ListResult()\n</code></pre>"},{"location":"api/result_manager/#anta.result_manager.ResultManager.__len__","title":"<code>__len__()</code>","text":"<p>Implement len method to count number of results.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def __len__(self) -&gt; int:\n\"\"\"\n    Implement __len__ method to count number of results.\n    \"\"\"\n    return len(self._result_entries)\n</code></pre>"},{"location":"api/result_manager/#anta.result_manager.ResultManager.add_test_result","title":"<code>add_test_result(entry)</code>","text":"<p>Add a result to the list</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <code>TestResult</code> <p>TestResult data to add to the report</p> required Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def add_test_result(self, entry: TestResult) -&gt; None:\n\"\"\"Add a result to the list\n\n    Args:\n        entry (TestResult): TestResult data to add to the report\n    \"\"\"\n    logger.info(f'add new test result to manager: {entry}')\n    self._result_entries.append(entry)\n</code></pre>"},{"location":"api/result_manager/#anta.result_manager.ResultManager.add_test_results","title":"<code>add_test_results(entries)</code>","text":"<p>Add a list of results to the list</p> <p>Parameters:</p> Name Type Description Default <code>entries</code> <code>List[TestResult]</code> <p>list of TestResult data to add to the report</p> required Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def add_test_results(self, entries: List[TestResult]) -&gt; None:\n\"\"\"Add a list of results to the list\n\n    Args:\n        entries (List[TestResult]): list of TestResult data to add to the report\n    \"\"\"\n    logger.info(f'add new list of results to manager: {[str(r) for r in entries]}')\n    self._result_entries.extend(entries)\n</code></pre>"},{"location":"api/result_manager/#anta.result_manager.ResultManager.get_hosts","title":"<code>get_hosts()</code>","text":"<p>Get list of IP addresses in current manager.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of IP addresses.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def get_hosts(self) -&gt; List[str]:\n\"\"\"\n    Get list of IP addresses in current manager.\n\n    Returns:\n        List[str]: List of IP addresses.\n    \"\"\"\n    logger.info('build list of host ip registered in result-manager')\n    result_list = []\n    for testcase in self._result_entries:\n        if str(testcase.name) not in result_list:\n            result_list.append(str(testcase.name))\n    logger.debug(f'list of tests name: {result_list}')\n    return result_list\n</code></pre>"},{"location":"api/result_manager/#anta.result_manager.ResultManager.get_result_by_host","title":"<code>get_result_by_host(host_ip, output_format='native')</code>","text":"<p>Get list of test result for a given host.</p> <p>Parameters:</p> Name Type Description Default <code>host_ip</code> <code>str</code> <p>IP Address of the host to use to filter results.</p> required <code>output_format</code> <code>str</code> <p>format selector. Can be either native/list. Defaults to \u2018native\u2019.</p> <code>'native'</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>List of results related to the host.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def get_result_by_host(self, host_ip: str, output_format: str = \"native\") -&gt; Any:\n\"\"\"\n    Get list of test result for a given host.\n\n    Args:\n        host_ip (str): IP Address of the host to use to filter results.\n        output_format (str, optional): format selector. Can be either native/list. Defaults to 'native'.\n\n    Returns:\n        Any: List of results related to the host.\n    \"\"\"\n    logger.info(\n        f'retrieve list of result using output_format {output_format} for host {host_ip}')\n    if output_format == \"list\":\n        return [\n            result for result in self._result_entries if str(result.name) == host_ip\n        ]\n\n    result_manager_filtered = ListResult()\n    for result in self._result_entries:\n        if str(result.name) == host_ip:\n            result_manager_filtered.append(result)\n    return result_manager_filtered\n</code></pre>"},{"location":"api/result_manager/#anta.result_manager.ResultManager.get_result_by_test","title":"<code>get_result_by_test(test_name, output_format='native')</code>","text":"<p>Get list of test result for a given test.</p> <p>Parameters:</p> Name Type Description Default <code>test_name</code> <code>str</code> <p>Test name to use to filter results</p> required <code>output_format</code> <code>str</code> <p>format selector. Can be either native/list. Defaults to \u2018native\u2019.</p> <code>'native'</code> <p>Returns:</p> Type Description <code>Any</code> <p>list[TestResult]: List of results related to the test.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def get_result_by_test(self, test_name: str, output_format: str = \"native\") -&gt; Any:\n\"\"\"\n    Get list of test result for a given test.\n\n    Args:\n        test_name (str): Test name to use to filter results\n        output_format (str, optional): format selector. Can be either native/list. Defaults to 'native'.\n\n    Returns:\n        list[TestResult]: List of results related to the test.\n    \"\"\"\n    logger.info(\n        f'retrieve list of result using output_format {output_format} for test {test_name}')\n    if output_format == \"list\":\n        return [\n            result\n            for result in self._result_entries\n            if str(result.test) == test_name\n        ]\n\n    result_manager_filtered = ListResult()\n    for result in self._result_entries:\n        if result.test == test_name:\n            result_manager_filtered.append(result)\n    return result_manager_filtered\n</code></pre>"},{"location":"api/result_manager/#anta.result_manager.ResultManager.get_results","title":"<code>get_results(output_format='native')</code>","text":"<p>Expose list of all test results in different format</p> Support multiple format <ul> <li>native: ListResults format</li> <li>list: a list of TestResult</li> <li>json: a native JSON format</li> </ul> <p>Parameters:</p> Name Type Description Default <code>output_format</code> <code>str</code> <p>format selector. Can be either native/list/json. Defaults to \u2018native\u2019.</p> <code>'native'</code> <p>Returns:</p> Name Type Description <code>any</code> <code>Any</code> <p>List of results.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def get_results(self, output_format: str = \"native\") -&gt; Any:\n\"\"\"\n    Expose list of all test results in different format\n\n    Support multiple format:\n      - native: ListResults format\n      - list: a list of TestResult\n      - json: a native JSON format\n\n    Args:\n        output_format (str, optional): format selector. Can be either native/list/json. Defaults to 'native'.\n\n    Returns:\n        any: List of results.\n    \"\"\"\n    logger.info(f'retrieve list of result using output_format {output_format}')\n    if output_format == 'list':\n        return list(self._result_entries)\n\n    if output_format == \"json\":\n        return json.dumps(pydantic_to_dict(self._result_entries), indent=4)\n\n    # Default return for native format.\n    return self._result_entries\n</code></pre>"},{"location":"api/result_manager/#anta.result_manager.ResultManager.get_testcases","title":"<code>get_testcases()</code>","text":"<p>Get list of name of all test cases in current manager.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of names for all tests.</p> Source code in <code>anta/result_manager/__init__.py</code> <pre><code>def get_testcases(self) -&gt; List[str]:\n\"\"\"\n    Get list of name of all test cases in current manager.\n\n    Returns:\n        List[str]: List of names for all tests.\n    \"\"\"\n    logger.info('build list of testcases registered in result-manager')\n    result_list = []\n    for testcase in self._result_entries:\n        if str(testcase.test) not in result_list:\n            result_list.append(str(testcase.test))\n    logger.debug(f'list of tests name: {result_list}')\n    return result_list\n</code></pre>"},{"location":"api/tests.configuration/","title":"Configuration","text":""},{"location":"api/tests.configuration/#anta-catalog-for-configuration-tests","title":"ANTA catalog for configuration tests","text":"<p>Test functions related to the device configuration</p>"},{"location":"api/tests.configuration/#anta.tests.configuration.verify_running_config_diffs","title":"<code>verify_running_config_diffs(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no difference between the running-config and the startup-config.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if there is no difference between the running-config and the startup-config</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d if there are differences</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/configuration.py</code> <pre><code>@anta_test\nasync def verify_running_config_diffs(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies there is no difference between the running-config and the startup-config.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if there is no difference between the running-config and the startup-config\n        * result = \"failure\" if there are differences\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    device.assert_enable_password_is_not_none(\"verify_running_config_diffs\")\n\n    response = await device.session.cli(\n        commands=[\n            {\"cmd\": \"enable\", \"input\": str(device.enable_password)},\n            \"show running-config diffs\",\n        ],\n        ofmt=\"text\"\n    )\n    logger.debug(f\"query result is: {response}\")\n\n    if len(response[1]) == 0:\n        result.is_success()\n\n    else:\n        result.is_failure()\n        for line in response[1].splitlines():\n            result.is_failure(line)\n\n    return result\n</code></pre>"},{"location":"api/tests.configuration/#anta.tests.configuration.verify_zerotouch","title":"<code>verify_zerotouch(device, result)</code>  <code>async</code>","text":"<p>Verifies ZeroTouch is disabled.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if ZTP is disabled</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d if ZTP is enabled</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/configuration.py</code> <pre><code>@anta_test\nasync def verify_zerotouch(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\n\"\"\"\n    Verifies ZeroTouch is disabled.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if ZTP is disabled\n        * result = \"failure\" if ZTP is enabled\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show zerotouch\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    if response[\"mode\"] == \"disabled\":\n        result.is_success()\n    else:\n        result.is_failure(\"ZTP is NOT disabled\")\n\n    return result\n</code></pre>"},{"location":"api/tests.hardware/","title":"Hardware","text":""},{"location":"api/tests.hardware/#anta-catalog-for-hardware-tests","title":"ANTA catalog for hardware tests","text":"<p>Test functions related to the hardware or environement</p>"},{"location":"api/tests.hardware/#anta.tests.hardware.verify_adverse_drops","title":"<code>verify_adverse_drops(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no adverse drops on DCS-7280E and DCS-7500E switches.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the device (DCS-7280E and DCS-7500E) doesnt reports adverse drops.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d if the device (DCS-7280E and DCS-7500E) report adverse drops.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/hardware.py</code> <pre><code>@skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n@anta_test\nasync def verify_adverse_drops(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\n\"\"\"\n    Verifies there is no adverse drops on DCS-7280E and DCS-7500E switches.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if the device (DCS-7280E and DCS-7500E) doesnt reports adverse drops.\n        * result = \"failure\" if the device (DCS-7280E and DCS-7500E) report adverse drops.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show hardware counter drop\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    if response[\"totalAdverseDrops\"] == 0:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"Device TotalAdverseDrops counter is {response['totalAdverseDrops']}.\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.hardware/#anta.tests.hardware.verify_environment_cooling","title":"<code>verify_environment_cooling(device, result)</code>  <code>async</code>","text":"<p>Verifies the fans status is OK.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the fans status is OK.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/hardware.py</code> <pre><code>@skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n@anta_test\nasync def verify_environment_cooling(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies the fans status is OK.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if the fans status is OK.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show system environment cooling\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    if response[\"systemStatus\"] == \"coolingOk\":\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"Device cooling is not OK, systemStatus: {response['systemStatus'] }\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.hardware/#anta.tests.hardware.verify_environment_power","title":"<code>verify_environment_power(device, result)</code>  <code>async</code>","text":"<p>Verifies the power supplies status is OK.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the power supplies status is OK.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/hardware.py</code> <pre><code>@skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n@anta_test\nasync def verify_environment_power(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\n\"\"\"\n    Verifies the power supplies status is OK.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if the power supplies status is OK.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show system environment power\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    wrong_power_supplies = {\n        powersupply: {\"state\": value[\"state\"]}\n        for powersupply, value in response[\"powerSupplies\"].items()\n        if value[\"state\"] != \"ok\"\n    }\n    if not wrong_power_supplies:\n        result.is_success()\n    else:\n        result.is_failure(\"The following power suppliers are not ok:\")\n        result.messages.append(str(wrong_power_supplies))\n\n    return result\n</code></pre>"},{"location":"api/tests.hardware/#anta.tests.hardware.verify_system_temperature","title":"<code>verify_system_temperature(device, result)</code>  <code>async</code>","text":"<p>Verifies the device temperature is currently OK and the device did not report any temperature alarm in the past.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the device temperature is OK.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/hardware.py</code> <pre><code>@skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n@anta_test\nasync def verify_system_temperature(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies the device temperature is currently OK\n    and the device did not report any temperature alarm in the past.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if the device temperature is OK.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(\n        command=\"show system environment temperature\", ofmt=\"json\"\n    )\n    logger.debug(f\"query result is: {response}\")\n\n    if response[\"systemStatus\"] == \"temperatureOk\":\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"Device temperature is not OK, systemStatus: {response['systemStatus'] }\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.hardware/#anta.tests.hardware.verify_transceiver_temperature","title":"<code>verify_transceiver_temperature(device, result)</code>  <code>async</code>","text":"<p>Verifies the transceivers temperature is currently OK and the device did not report any alarm in the past for its transceivers temperature.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the device transceivers temperature of the device is currently OK                  AND the device did not report any alarm in the past for its transceivers temperature.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise,</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/hardware.py</code> <pre><code>@skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n@anta_test\nasync def verify_transceiver_temperature(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies the transceivers temperature is currently OK\n    and the device did not report any alarm in the past for its transceivers temperature.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if the device transceivers temperature of the device is currently OK\n                             AND the device did not report any alarm in the past for its transceivers temperature.\n        * result = \"failure\" otherwise,\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(\n        command=\"show system environment temperature transceiver\", ofmt=\"json\"\n    )\n    logger.debug(f\"query result is: {response}\")\n\n    # Get the list of sensors\n    sensors = response[\"tempSensors\"]\n\n    wrong_sensors = {\n        sensor[\"name\"]: {\n            \"hwStatus\": sensor[\"hwStatus\"],\n            \"alertCount\": sensor[\"alertCount\"],\n        }\n        for sensor in sensors\n        if sensor[\"hwStatus\"] != \"ok\" or sensor[\"alertCount\"] != 0\n    }\n    if not wrong_sensors:\n        result.is_success()\n    else:\n        result.is_failure(\n            \"The following sensors do not have the correct temperature or had alarms in the past:\"\n        )\n        result.messages.append(str(wrong_sensors))\n\n    return result\n</code></pre>"},{"location":"api/tests.hardware/#anta.tests.hardware.verify_transceivers_manufacturers","title":"<code>verify_transceivers_manufacturers(device, result, manufacturers=None)</code>  <code>async</code>","text":"<p>Verifies the device is only using transceivers from supported manufacturers.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>manufacturers</code> <code>list</code> <p>List of allowed transceivers manufacturers.</p> <code>None</code> <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the test was not executed because no manufacturers were given</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the device is only using transceivers from supported manufacturers.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/hardware.py</code> <pre><code>@skip_on_platforms([\"cEOSLab\", \"vEOS-lab\"])\n@anta_test\nasync def verify_transceivers_manufacturers(\n    device: InventoryDevice,\n    result: TestResult,\n    manufacturers: Optional[List[str]] = None,\n) -&gt; TestResult:\n\"\"\"\n    Verifies the device is only using transceivers from supported manufacturers.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        manufacturers (list): List of allowed transceivers manufacturers.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the test was not executed because no manufacturers were given\n        * result = \"success\" if the device is only using transceivers from supported manufacturers.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n\n    if not manufacturers:\n        result.is_skipped(\n            \"verify_transceivers_manufacturers was not run as no \"\n            \"manufacturers were given\"\n        )\n        return result\n\n    response = await device.session.cli(command=\"show inventory\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    wrong_manufacturers = {\n        interface: value[\"mfgName\"]\n        for interface, value in response[\"xcvrSlots\"].items()\n        if value[\"mfgName\"] not in manufacturers\n    }\n\n    if not wrong_manufacturers:\n        result.is_success()\n    else:\n        result.is_failure(\n            \"The following interfaces have transceivers from unauthorized manufacturers\"\n        )\n        result.messages.append(str(wrong_manufacturers))\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/","title":"Interfaces","text":""},{"location":"api/tests.interfaces/#anta-catalog-for-interfaces-tests","title":"ANTA catalog for interfaces tests","text":"<p>Test functions related to the device interfaces</p>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_illegal_lacp","title":"<code>verify_illegal_lacp(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no illegal LACP packets received.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if there is no illegal LACP packets received.                  in particular \u201csuccess\u201d if there is no port-channel</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@anta_test\nasync def verify_illegal_lacp(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\n\"\"\"\n    Verifies there is no illegal LACP packets received.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if there is no illegal LACP packets received.\n                             in particular \"success\" if there is no port-channel\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show lacp counters all-ports\", ofmt=\"json\")\n\n    po_with_illegal_lacp = {\n        portchannel: [\n            interface\n            for interface, interface_dict in portchannel_dict[\"interfaces\"].items()\n            if interface_dict[\"illegalRxCount\"] != 0\n        ]\n        for portchannel, portchannel_dict in response[\"portChannels\"].items()\n    }\n\n    if len(po_with_illegal_lacp) == 0:\n        result.is_success()\n    else:\n        result.is_failure(\n            \"The following port-channels have recieved illegal lacp packets on the \"\n            f\"following ports: {po_with_illegal_lacp}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_interface_discards","title":"<code>verify_interface_discards(device, result)</code>  <code>async</code>","text":"<p>Verifies interfaces packet discard counters are equal to zero.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if interfaces discard counters are equal to zero.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@anta_test\nasync def verify_interface_discards(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies interfaces packet discard counters are equal to zero.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if interfaces discard counters are equal to zero.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show interfaces counters discards\", ofmt=\"json\")\n\n    wrong_interfaces = {\n        interface: {counter: value for counter, value in outer_v.items() if value &gt; 0}\n        for interface, outer_v in response[\"interfaces\"].items()\n    }\n    if len(wrong_interfaces) == 0:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"The following interfaces have non 0 discard counter(s): {wrong_interfaces}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_interface_errdisabled","title":"<code>verify_interface_errdisabled(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no interface in error disable state.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if no interface is in error disable state.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@anta_test\nasync def verify_interface_errdisabled(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies there is no interface in error disable state.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if no interface is in error disable state.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show interfaces status\", ofmt=\"json\")\n\n    errdisabled_interfaces = [\n        interface\n        for interface, value in response[\"interfaceStatuses\"].items()\n        if value[\"linkStatus\"] == \"errdisabled\"\n    ]\n\n    if len(errdisabled_interfaces) == 0:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"The following interfaces are in error disabled state: {errdisabled_interfaces}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_interface_errors","title":"<code>verify_interface_errors(device, result)</code>  <code>async</code>","text":"<p>Verifies interfaces error counters are equal to zero.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if interfaces error counters are equal to zero.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@anta_test\nasync def verify_interface_errors(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\n\"\"\"\n    Verifies interfaces error counters are equal to zero.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if interfaces error counters are equal to zero.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show interfaces counters errors\", ofmt=\"json\")\n\n    wrong_interfaces = {\n        interface: {counter: value for counter, value in outer_v.items() if value &gt; 0}\n        for interface, outer_v in response[\"interfaceErrorCounters\"].items()\n    }\n    if len(wrong_interfaces) == 0:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"The following interfaces have non 0 error counter(s): {wrong_interfaces}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_interface_utilization","title":"<code>verify_interface_utilization(device, result)</code>  <code>async</code>","text":"<p>Verifies interfaces utilization is below 75%.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if interfaces utilization is below 75%</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@anta_test\nasync def verify_interface_utilization(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies interfaces utilization is below 75%.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if interfaces utilization is below 75%\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    # TODO make it JSON - bad news it seems percentages are not in the json payload\n    response = await device.session.cli(command=\"show interfaces counters rates\", ofmt=\"text\")\n\n    wrong_interfaces = {}\n    for line in response.split(\"\\n\")[1:]:\n        if len(line) &gt; 0:\n            if line.split()[-5] == \"-\" or line.split()[-2] == \"-\":\n                pass\n            elif float(line.split()[-5].replace(\"%\", \"\")) &gt; 75.0:\n                wrong_interfaces[line.split()[0]] = line.split()[-5]\n            elif float(line.split()[-2].replace(\"%\", \"\")) &gt; 75.0:\n                wrong_interfaces[line.split()[0]] = line.split()[-2]\n\n    if not wrong_interfaces:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"The following interfaces have a usage &gt; 75%: {wrong_interfaces}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_interfaces_status","title":"<code>verify_interfaces_status(device, result, minimum=None)</code>  <code>async</code>","text":"<p>Verifies the number of Ethernet interfaces up/up on the device is higher or equal than a value.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>minimum</code> <code>int</code> <p>Expected minimum number of Ethernet interfaces up/up</p> <code>None</code> <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the <code>minimum</code> parameter is missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the number of Ethernet interface up/up is &gt;= minimum</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@anta_test\nasync def verify_interfaces_status(\n    device: InventoryDevice, result: TestResult, minimum: Optional[int] = None\n) -&gt; TestResult:\n\"\"\"\n    Verifies the number of Ethernet interfaces up/up on the device is higher or equal than a value.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        minimum (int): Expected minimum number of Ethernet interfaces up/up\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the `minimum` parameter is missing\n        * result = \"success\" if the number of Ethernet interface up/up is &gt;= minimum\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    if not minimum:\n        result.result = \"skipped\"\n        result.messages.append(\n            \"verify_interfaces_status was not run as no minimum value was given.\"\n        )\n        return result\n\n    response = await device.session.cli(command=\"show interfaces description\", ofmt=\"json\")\n\n    count_up_up = 0\n    other_ethernet_interfaces = []\n\n    for interface in response[\"interfaceDescriptions\"]:\n        interface_dict = response[\"interfaceDescriptions\"][interface]\n        if \"Ethernet\" in interface:\n            if (\n                interface_dict[\"lineProtocolStatus\"] == \"up\"\n                and interface_dict[\"interfaceStatus\"] == \"connected\"\n            ):\n                count_up_up += 1\n            else:\n                other_ethernet_interfaces.append(interface)\n\n    if count_up_up &gt;= minimum:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"Only {count_up_up}, less than {minimum} Ethernet interfaces are UP/UP\"\n        )\n        result.messages.append(\n            f\"The following Ethernet interfaces are not UP/UP: {other_ethernet_interfaces}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_loopback_count","title":"<code>verify_loopback_count(device, result, number=None)</code>  <code>async</code>","text":"<p>Verifies the number of loopback interfaces on the device is the one we expect. And if none of the loopback is down.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>number</code> <code>int</code> <p>Expected number of loopback interfaces.</p> <code>None</code> <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the number of loopback is equal to <code>number</code> and if                  none of the loopback is down</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@anta_test\nasync def verify_loopback_count(\n    device: InventoryDevice, result: TestResult, number: Optional[int] = None\n) -&gt; TestResult:\n\"\"\"\n    Verifies the number of loopback interfaces on the device is the one we expect.\n    And if none of the loopback is down.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        number (int): Expected number of loopback interfaces.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if the number of loopback is equal to `number` and if\n                             none of the loopback is down\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    if not number:\n        result.is_skipped(\n            \"verify_loopback_count was not run as no number value was given.\"\n        )\n        return result\n\n    response = await device.session.cli(command=\"show ip interface brief \", ofmt=\"json\")\n\n    loopback_count = 0\n    down_loopback_interfaces = []\n\n    for interface in response[\"interfaces\"]:\n        interface_dict = response[\"interfaces\"][interface]\n        if \"Loopback\" in interface:\n            loopback_count += 1\n            if not (\n                interface_dict[\"lineProtocolStatus\"] == \"up\"\n                and interface_dict[\"interfaceStatus\"] == \"connected\"\n            ):\n                down_loopback_interfaces.append(interface)\n\n    if loopback_count == number and len(down_loopback_interfaces) == 0:\n        result.is_success()\n    else:\n        result.is_failure()\n        if loopback_count != number:\n            result.is_failure(\n                f\"Found {loopback_count} Loopbacks when expecting {number}\"\n            )\n        elif len(down_loopback_interfaces) != 0:\n            result.is_failure(\n                f\"The following Loopbacks are not up: {down_loopback_interfaces}\"\n            )\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_portchannels","title":"<code>verify_portchannels(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no inactive port in port channels.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if there is no inactive ports in port-channels                  in particular \u201csuccess\u201d if there is no port-channel</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@anta_test\nasync def verify_portchannels(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\n\"\"\"\n    Verifies there is no inactive port in port channels.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if there is no inactive ports in port-channels\n                             in particular \"success\" if there is no port-channel\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show port-channel\", ofmt=\"json\")\n\n    po_with_invactive_ports = {\n        portchannel: {\"inactivePorts\": portchannel_dict[\"inactivePorts\"]}\n        for portchannel, portchannel_dict in response[\"portChannels\"].items()\n        if len(portchannel_dict[\"inactivePorts\"]) != 0\n    }\n\n    if len(po_with_invactive_ports) == 0:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"The following port-channels have inactive port(s): {po_with_invactive_ports}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_spanning_tree_blocked_ports","title":"<code>verify_spanning_tree_blocked_ports(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no spanning-tree blocked ports.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if there is no spanning-tree blocked ports</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@anta_test\nasync def verify_spanning_tree_blocked_ports(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies there is no spanning-tree blocked ports.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if there is no spanning-tree blocked ports\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show spanning-tree blockedports\", ofmt=\"json\")\n\n    if len(response[\"spanningTreeInstances\"]) == 0:\n        result.is_success()\n    else:\n        result.is_failure()\n        # TODO: a bit lazy would need a real output for this\n        result.messages.append(\n            f\"The following ports are spanning-tree blocked {response['spanningTreeInstances']}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_storm_control_drops","title":"<code>verify_storm_control_drops(device, result)</code>  <code>async</code>","text":"<p>Verifies the device did not drop packets due its to storm-control configuration.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the device did not drop packet due to its storm-control configuration.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@skip_on_platforms([\"cEOSLab\", \"VEOS-LAB\"])\n@anta_test\nasync def verify_storm_control_drops(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\"\"\"\n    Verifies the device did not drop packets due its to storm-control configuration.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if the device did not drop packet due to its storm-control configuration.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show storm-control\", ofmt=\"json\")\n\n    storm_controlled_interfaces: Dict[str, Dict[str, Any]] = {}\n    for interface, interface_dict in response[\"interfaces\"].items():\n        for traffic_type, traffic_type_dict in interface_dict[\"trafficTypes\"]:\n            if \"drop\" in traffic_type_dict and traffic_type_dict[\"drop\"] != 0:\n                storm_controlled_interface_dict = (\n                    storm_controlled_interfaces.setdefault(interface, {})\n                )\n                storm_controlled_interface_dict.update(\n                    {traffic_type: traffic_type_dict[\"drop\"]}\n                )\n\n    if len(storm_controlled_interfaces) == 0:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"The following interfaces have none 0 storm-control drop counters {storm_controlled_interfaces}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.interfaces/#anta.tests.interfaces.verify_svi","title":"<code>verify_svi(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no interface vlan down.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if no SVI is down</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/interfaces.py</code> <pre><code>@anta_test\nasync def verify_svi(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\"\"\"\n    Verifies there is no interface vlan down.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if no SVI is down\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show ip interface brief\", ofmt=\"json\")\n\n    down_svis = []\n\n    for interface in response[\"interfaces\"]:\n        interface_dict = response[\"interfaces\"][interface]\n        if \"Vlan\" in interface:\n            if not (\n                interface_dict[\"lineProtocolStatus\"] == \"up\"\n                and interface_dict[\"interfaceStatus\"] == \"connected\"\n            ):\n                down_svis.append(interface)\n\n    if len(down_svis) == 0:\n        result.is_success()\n    else:\n        result.is_failure(f\"The following SVIs are not up: {down_svis}\")\n\n    return result\n</code></pre>"},{"location":"api/tests/","title":"Overview","text":""},{"location":"api/tests/#anta-tests-landing-page","title":"ANTA Tests landing page","text":"<p>This section describes all the available tests provided by ANTA package.</p> <ul> <li>Configuration</li> <li>Hardware</li> <li>interfaces</li> <li>MLAG</li> <li>Multicast</li> <li>Profiles</li> <li>System</li> <li>Software</li> <li>Routing Generic</li> <li>Routing BGP</li> <li>Routing OSPF</li> </ul> <p>Al these tests can be imported in a catalog to be used by <code>check-devices.py</code> script.</p>"},{"location":"api/tests.mlag/","title":"MLAG","text":""},{"location":"api/tests.mlag/#anta-catalog-for-mlag-tests","title":"ANTA catalog for mlag tests","text":"<p>Test functions related to Multi-Chassis LAG</p>"},{"location":"api/tests.mlag/#anta.tests.mlag.verify_mlag_config_sanity","title":"<code>verify_mlag_config_sanity(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no MLAG config-sanity inconsistencies.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if there is no MLAG config-sanity inconsistencies</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/mlag.py</code> <pre><code>@anta_test\nasync def verify_mlag_config_sanity(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\"\"\"\n    Verifies there is no MLAG config-sanity inconsistencies.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if there is no MLAG config-sanity inconsistencies\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show mlag config-sanity\", ofmt=\"json\")\n\n    if \"mlagActive\" not in response.keys():\n        result.is_error(\"incorrect JSON response\")\n    elif response[\"mlagActive\"] is False:\n        # MLAG is not running\n        result.is_skipped(\"MLAG is disabled\")\n    elif (\n        len(response[\"globalConfiguration\"]) &gt; 0\n        or len(response[\"interfaceConfiguration\"]) &gt; 0\n    ):\n        result.is_failure()\n        if len(response[\"globalConfiguration\"]) &gt; 0:\n            result.is_failure(\n                \"MLAG config-sanity returned some Global inconsistencies: \"\n                f\"{response['response']['globalConfiguration']}\"\n            )\n        if len(response[\"interfaceConfiguration\"]) &gt; 0:\n            result.is_failure(\n                \"MLAG config-sanity returned some Interface inconsistencies: \"\n                f\"{response['response']['interfaceConfiguration']}\"\n            )\n    else:\n        result.is_success()\n\n    return result\n</code></pre>"},{"location":"api/tests.mlag/#anta.tests.mlag.verify_mlag_interfaces","title":"<code>verify_mlag_interfaces(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no inactive or active-partial MLAG interfaces.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if there is no inactive or active-partial MLAG interfaces.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/mlag.py</code> <pre><code>@anta_test\nasync def verify_mlag_interfaces(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\"\"\"\n    Verifies there is no inactive or active-partial MLAG interfaces.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if there is no inactive or active-partial MLAG interfaces.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show mlag\", ofmt=\"json\")\n\n    if response[\"state\"] == \"disabled\":\n        result.is_skipped(\"MLAG is disabled\")\n    elif (\n        response[\"mlagPorts\"][\"Inactive\"] != 0\n        or response[\"mlagPorts\"][\"Active-partial\"] != 0\n    ):\n        result.is_failure(f\"MLAG status is not OK: {response['mlagPorts']}\")\n    else:\n        result.is_success()\n\n    return result\n</code></pre>"},{"location":"api/tests.mlag/#anta.tests.mlag.verify_mlag_status","title":"<code>verify_mlag_status(device, result)</code>  <code>async</code>","text":"<p>Verifies the MLAG status: state is active, negotiation status is connected, local int is up, peer link is up.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the MLAG status is OK</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/mlag.py</code> <pre><code>@anta_test\nasync def verify_mlag_status(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\"\"\"\n    Verifies the MLAG status:\n    state is active, negotiation status is connected, local int is up, peer link is up.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if the MLAG status is OK\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show mlag\", ofmt=\"json\")\n\n    if response[\"state\"] == \"disabled\":\n        result.is_skipped(\"MLAG is disabled\")\n    elif (\n        response[\"state\"] != \"active\"\n        or response[\"negStatus\"] != \"connected\"\n        or response[\"localIntfStatus\"] != \"up\"\n        or response[\"peerLinkStatus\"] != \"up\"\n    ):\n        result.is_failure(f\"MLAG status is not OK: {response}\")\n    else:\n        result.is_success()\n\n    return result\n</code></pre>"},{"location":"api/tests.multicast/","title":"Multicast","text":""},{"location":"api/tests.multicast/#anta-catalog-for-multicast-tests","title":"ANTA catalog for multicast tests","text":"<p>Test functions related to multicast</p>"},{"location":"api/tests.multicast/#anta.tests.multicast.verify_igmp_snooping_global","title":"<code>verify_igmp_snooping_global(device, result, configuration)</code>  <code>async</code>","text":"<p>Verifies the IGMP snooping global configuration.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>configuration</code> <code>str</code> <p>Expected global IGMP snooping configuration (enabled or disabled).</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the <code>configuration</code> parameter was missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if IGMP snooping is globally configured</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/multicast.py</code> <pre><code>@anta_test\nasync def verify_igmp_snooping_global(\n    device: InventoryDevice, result: TestResult, configuration: str\n) -&gt; TestResult:\n\"\"\"\n    Verifies the IGMP snooping global configuration.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        configuration (str): Expected global IGMP snooping configuration (enabled or disabled).\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the `configuration` parameter was missing\n        * result = \"success\" if IGMP snooping is globally configured\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    if not configuration:\n        result.is_skipped(\n            \"verify_igmp_snooping_global was not run as no configuration was given\"\n        )\n        return result\n\n    response = await device.session.cli(command=\"show ip igmp snooping\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    igmp_state = response[\"igmpSnoopingState\"]\n    if igmp_state == configuration:\n        result.is_success()\n    else:\n        result.is_failure(f\"IGMP state is not valid: {igmp_state}\")\n\n    return result\n</code></pre>"},{"location":"api/tests.multicast/#anta.tests.multicast.verify_igmp_snooping_vlans","title":"<code>verify_igmp_snooping_vlans(device, result, vlans, configuration)</code>  <code>async</code>","text":"<p>Verifies the IGMP snooping configuration for some VLANs.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>vlans</code> <code>List[str]</code> <p>A list of VLANs</p> required <code>configuration</code> <code>str</code> <p>Expected IGMP snooping configuration (enabled or disabled) for these VLANs.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if IGMP snooping is configured on these vlans</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/multicast.py</code> <pre><code>@anta_test\nasync def verify_igmp_snooping_vlans(\n    device: InventoryDevice, result: TestResult, vlans: List[str], configuration: str\n) -&gt; TestResult:\n\"\"\"\n    Verifies the IGMP snooping configuration for some VLANs.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        vlans (List[str]): A list of VLANs\n        configuration (str): Expected IGMP snooping configuration (enabled or disabled) for these VLANs.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if IGMP snooping is configured on these vlans\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    if not vlans or not configuration:\n        result.result = \"skipped\"\n        result.messages.append(\n            \"verify_igmp_snooping_vlans was not run as no \"\n            \"vlans or configuration was given\"\n        )\n        return result\n    response = await device.session.cli(command=\"show ip igmp snooping\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    result.is_success()\n    for vlan in vlans:\n        if vlan not in response[\"vlans\"]:\n            result.is_failure(f\"Supplied vlan {vlan} is not present on the device.\")\n            continue\n\n        igmp_state = response[\"vlans\"][str(vlan)][\"igmpSnoopingState\"]\n        if igmp_state != configuration:\n            result.is_failure()\n            result.messages.append(f\"IGMP state for vlan {vlan} is {igmp_state}\")\n\n    return result\n</code></pre>"},{"location":"api/tests.profiles/","title":"Profiles","text":""},{"location":"api/tests.profiles/#anta-catalog-for-profiles-tests","title":"ANTA catalog for profiles tests","text":"<p>Test functions related to ASIC profiles</p>"},{"location":"api/tests.profiles/#anta.tests.profiles.verify_tcam_profile","title":"<code>verify_tcam_profile(device, result, profile)</code>  <code>async</code>","text":"<p>Verifies the configured TCAM profile is the expected one.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>profile</code> <code>str</code> <p>The expected TCAM profile.0</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cmode\u201d if the <code>profile</code> parameter is missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if TCAM profile is correct</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/profiles.py</code> <pre><code>@skip_on_platforms([\"cEOSLab\", \"VEOS-LAB\"])\n@anta_test\nasync def verify_tcam_profile(\n    device: InventoryDevice, result: TestResult, profile: str\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies the configured TCAM profile is the expected one.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        profile (str): The expected TCAM profile.0\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"mode\" if the `profile` parameter is missing\n        * result = \"success\" if TCAM profile is correct\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    if not profile:\n        result.is_skipped(\"verify_tcam_profile was not run as no profile was given\")\n        return result\n\n    response = await device.session.cli(command=\"show hardware tcam profile\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n    if (\n        response[\"pmfProfiles\"][\"FixedSystem\"][\"status\"]\n        == response[\"pmfProfiles\"][\"FixedSystem\"][\"config\"]\n    ) and (response[\"pmfProfiles\"][\"FixedSystem\"][\"status\"] == profile):\n        result.is_success()\n    else:\n        result.is_failure(\n            f'Incorrect profile configured on device: {response[\"pmfProfiles\"][\"FixedSystem\"][\"status\"]}'\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.profiles/#anta.tests.profiles.verify_unified_forwarding_table_mode","title":"<code>verify_unified_forwarding_table_mode(device, result, mode)</code>  <code>async</code>","text":"<p>Verifies the device is using the expected Unified Forwarding Table mode.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>mode</code> <code>str</code> <p>The expected Unified Forwarding Table mode.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cmode\u201d if the <code>mode</code> parameter is missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if UFT mode is correct</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/profiles.py</code> <pre><code>@skip_on_platforms([\"cEOSLab\", \"VEOS-LAB\"])\n@anta_test\nasync def verify_unified_forwarding_table_mode(\n    device: InventoryDevice, result: TestResult, mode: str\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies the device is using the expected Unified Forwarding Table mode.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        mode (str): The expected Unified Forwarding Table mode.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"mode\" if the `mode` parameter is missing\n        * result = \"success\" if UFT mode is correct\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    if not mode:\n        result.is_skipped(\n            \"verify_unified_forwarding_table_mode was not run as no mode was given\"\n        )\n        return result\n\n    response = await device.session.cli(command=\"show platform trident forwarding-table partition\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n    response_data = response[\"uftMode\"]\n    if response_data == mode:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"device is not running correct UFT mode (expected: {mode} / running: {response_data})\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.bgp/","title":"BGP","text":""},{"location":"api/tests.routing.bgp/#anta-catalog-for-routing-bgp-tests","title":"ANTA catalog for routing-bgp tests","text":"<p>BGP test functions</p>"},{"location":"api/tests.routing.bgp/#anta.tests.routing.bgp.verify_bgp_evpn_count","title":"<code>verify_bgp_evpn_count(device, result, number)</code>  <code>async</code>","text":"<p>Verifies all EVPN BGP sessions are established (default VRF) and the actual number of BGP EVPN neighbors is the one we expect (default VRF).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>number</code> <code>int</code> <p>The expected number of BGP EVPN neighbors in the default VRF.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the <code>number</code> parameter is missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if all EVPN BGP sessions are Established and if the actual                  number of BGP EVPN neighbors is the one we expect.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>@anta_test\n@check_bgp_family_enable(\"evpn\")\nasync def verify_bgp_evpn_count(\n    device: InventoryDevice, result: TestResult, number: int\n) -&gt; TestResult:\n\"\"\"\n    Verifies all EVPN BGP sessions are established (default VRF)\n    and the actual number of BGP EVPN neighbors is the one we expect (default VRF).\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        number (int): The expected number of BGP EVPN neighbors in the default VRF.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the `number` parameter is missing\n        * result = \"success\" if all EVPN BGP sessions are Established and if the actual\n                             number of BGP EVPN neighbors is the one we expect.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    if not number:\n        result.is_skipped(\n            \"verify_bgp_evpn_count could not run because number was not supplied.\"\n        )\n        return result\n\n    response = await device.session.cli(command=\"show bgp evpn summary\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    peers = response[\"vrfs\"][\"default\"][\"peers\"]\n\n    if len(peers) == number:\n        result.is_success()\n    else:\n        result.is_failure()\n        if len(peers) != number:\n            result.messages.append(\n                f\"Expecting {number} BGP EVPN peers and got {len(peers)}\"\n            )\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.bgp/#anta.tests.routing.bgp.verify_bgp_evpn_state","title":"<code>verify_bgp_evpn_state(device, result)</code>  <code>async</code>","text":"<p>Verifies all EVPN BGP sessions are established (default VRF).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if no BGP EVPN peers are returned by the device</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if all EVPN BGP sessions are established.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>@anta_test\n@check_bgp_family_enable(\"evpn\")\nasync def verify_bgp_evpn_state(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\n\"\"\"\n    Verifies all EVPN BGP sessions are established (default VRF).\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if no BGP EVPN peers are returned by the device\n        * result = \"success\" if all EVPN BGP sessions are established.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show bgp evpn summary\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    bgp_vrfs = response[\"vrfs\"]\n\n    peers = bgp_vrfs[\"default\"][\"peers\"]\n    non_established_peers = [\n        peer\n        for peer, peer_dict in peers.items()\n        if peer_dict[\"peerState\"] != \"Established\"\n    ]\n\n    if not non_established_peers:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"The following EVPN peers are not established: {non_established_peers}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.bgp/#anta.tests.routing.bgp.verify_bgp_ipv4_unicast_count","title":"<code>verify_bgp_ipv4_unicast_count(device, result, number, vrf='default')</code>  <code>async</code>","text":"<p>Verifies all IPv4 unicast BGP sessions are established and all BGP messages queues for these sessions are empty and the actual number of BGP IPv4 unicast neighbors is the one we expect.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>number</code> <code>int</code> <p>Expected number of BGP IPv4 unicast neighbors</p> required <code>vrf(str)</code> <p>VRF to verify. default is \u201cdefault\u201d.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the <code>number</code> or <code>vrf</code> parameter is missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if all IPv4 unicast BGP sessions are established                  and if all BGP messages queues for these sessions are empty                  and if the actual number of BGP IPv4 unicast neighbors is equal to `number.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>@anta_test\n@check_bgp_family_enable(\"ipv4\")\nasync def verify_bgp_ipv4_unicast_count(\n    device: InventoryDevice, result: TestResult, number: int, vrf: str = \"default\"\n) -&gt; TestResult:\n\"\"\"\n    Verifies all IPv4 unicast BGP sessions are established\n    and all BGP messages queues for these sessions are empty\n    and the actual number of BGP IPv4 unicast neighbors is the one we expect.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        number (int): Expected number of BGP IPv4 unicast neighbors\n        vrf(str): VRF to verify. default is \"default\".\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the `number` or `vrf` parameter is missing\n        * result = \"success\" if all IPv4 unicast BGP sessions are established\n                             and if all BGP messages queues for these sessions are empty\n                             and if the actual number of BGP IPv4 unicast neighbors is equal to `number.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    if not number or not vrf:\n        result.is_skipped(\n            \"verify_bgp_ipv4_unicast_count could not run because number of vrf was not supplied\"\n        )\n        return result\n\n    response = await device.session.cli(\n        command=f\"show bgp ipv4 unicast summary vrf {vrf}\", ofmt=\"json\"\n    )\n    logger.debug(f\"query result is: {response}\")\n\n    bgp_vrfs = response[\"vrfs\"]\n\n    peer_state_issue = {}\n    peer_number = len(bgp_vrfs[vrf][\"peers\"])\n\n    for peer in bgp_vrfs[vrf][\"peers\"]:\n        if (\n            (bgp_vrfs[vrf][\"peers\"][peer][\"peerState\"] != \"Established\")\n            or (bgp_vrfs[vrf][\"peers\"][peer][\"inMsgQueue\"] != 0)\n            or (bgp_vrfs[vrf][\"peers\"][peer][\"outMsgQueue\"] != 0)\n        ):\n            peer_state_issue[peer] = {\n                \"peerState\": bgp_vrfs[vrf][\"peers\"][peer][\"peerState\"],\n                \"inMsgQueue\": bgp_vrfs[vrf][\"peers\"][peer][\"inMsgQueue\"],\n                \"outMsgQueue\": bgp_vrfs[vrf][\"peers\"][peer][\"outMsgQueue\"],\n            }\n\n    if peer_number == number:\n        result.is_success()\n    else:\n        result.is_failure()\n        if peer_number != number:\n            result.is_failure(\n                f\"Expecting {number} BGP peer in vrf {vrf} and got {peer_number}\"\n            )\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.bgp/#anta.tests.routing.bgp.verify_bgp_ipv4_unicast_state","title":"<code>verify_bgp_ipv4_unicast_state(device, result)</code>  <code>async</code>","text":"<p>Verifies all IPv4 unicast BGP sessions are established (for all VRF) and all BGP messages queues for these sessions are empty (for all VRF).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if no BGP vrf are returned by the device</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if all IPv4 unicast BGP sessions are established (for all VRF)                  and all BGP messages queues for these sessions are empty (for all VRF).</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>@anta_test\n@check_bgp_family_enable(\"ipv4\")\nasync def verify_bgp_ipv4_unicast_state(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\"\"\"\n    Verifies all IPv4 unicast BGP sessions are established (for all VRF)\n    and all BGP messages queues for these sessions are empty (for all VRF).\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if no BGP vrf are returned by the device\n        * result = \"success\" if all IPv4 unicast BGP sessions are established (for all VRF)\n                             and all BGP messages queues for these sessions are empty (for all VRF).\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    response = await device.session.cli(\n        command=\"show bgp ipv4 unicast summary vrf all\", ofmt=\"json\"\n    )\n    logger.debug(f\"query result is: {response}\")\n\n    bgp_vrfs = response[\"vrfs\"]\n\n    state_issue: Dict[str, Any] = {}\n    for vrf in bgp_vrfs:\n        for peer in bgp_vrfs[vrf][\"peers\"]:\n            if (\n                (bgp_vrfs[vrf][\"peers\"][peer][\"peerState\"] != \"Established\")\n                or (bgp_vrfs[vrf][\"peers\"][peer][\"inMsgQueue\"] != 0)\n                or (bgp_vrfs[vrf][\"peers\"][peer][\"outMsgQueue\"] != 0)\n            ):\n                vrf_dict = state_issue.setdefault(vrf, {})\n                vrf_dict.update(\n                    {\n                        peer: {\n                            \"peerState\": bgp_vrfs[vrf][\"peers\"][peer][\"peerState\"],\n                            \"inMsgQueue\": bgp_vrfs[vrf][\"peers\"][peer][\"inMsgQueue\"],\n                            \"outMsgQueue\": bgp_vrfs[vrf][\"peers\"][peer][\"outMsgQueue\"],\n                        }\n                    }\n                )\n\n    if not state_issue:\n        result.is_success()\n    else:\n        result.is_failure(f\"Some IPv4 Unicast BGP Peer are not up: {state_issue}\")\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.bgp/#anta.tests.routing.bgp.verify_bgp_ipv6_unicast_state","title":"<code>verify_bgp_ipv6_unicast_state(device, result)</code>  <code>async</code>","text":"<p>Verifies all IPv6 unicast BGP sessions are established (for all VRF) and all BGP messages queues for these sessions are empty (for all VRF).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if no BGP vrf are returned by the device</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if all IPv6 unicast BGP sessions are established (for all VRF)                  and all BGP messages queues for these sessions are empty (for all VRF).</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>@anta_test\n@check_bgp_family_enable(\"ipv6\")\nasync def verify_bgp_ipv6_unicast_state(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\"\"\"\n    Verifies all IPv6 unicast BGP sessions are established (for all VRF)\n    and all BGP messages queues for these sessions are empty (for all VRF).\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if no BGP vrf are returned by the device\n        * result = \"success\" if all IPv6 unicast BGP sessions are established (for all VRF)\n                             and all BGP messages queues for these sessions are empty (for all VRF).\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    response = await device.session.cli(\n        command=\"show bgp ipv6 unicast summary vrf all\", ofmt=\"json\"\n    )\n\n    logger.debug(f\"query result is: {response}\")\n    bgp_vrfs = response[\"vrfs\"]\n\n    state_issue: Dict[str, Any] = {}\n    for vrf in bgp_vrfs:\n        for peer in bgp_vrfs[vrf][\"peers\"]:\n            if (\n                (bgp_vrfs[vrf][\"peers\"][peer][\"peerState\"] != \"Established\")\n                or (bgp_vrfs[vrf][\"peers\"][peer][\"inMsgQueue\"] != 0)\n                or (bgp_vrfs[vrf][\"peers\"][peer][\"outMsgQueue\"] != 0)\n            ):\n                vrf_dict = state_issue.setdefault(vrf, {})\n                vrf_dict.update(\n                    {\n                        peer: {\n                            \"peerState\": bgp_vrfs[vrf][\"peers\"][peer][\"peerState\"],\n                            \"inMsgQueue\": bgp_vrfs[vrf][\"peers\"][peer][\"inMsgQueue\"],\n                            \"outMsgQueue\": bgp_vrfs[vrf][\"peers\"][peer][\"outMsgQueue\"],\n                        }\n                    }\n                )\n\n    if not state_issue:\n        result.is_success()\n    else:\n        result.is_failure(f\"Some IPv6 Unicast BGP Peer are not up: {state_issue}\")\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.bgp/#anta.tests.routing.bgp.verify_bgp_rtc_count","title":"<code>verify_bgp_rtc_count(device, result, number)</code>  <code>async</code>","text":"<p>Verifies all RTC BGP sessions are established (default VRF) and the actual number of BGP RTC neighbors is the one we expect (default VRF).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>number</code> <code>int</code> <p>The expected number of BGP RTC neighbors (default VRF).</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the <code>number</code> parameter is missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if all RTC BGP sessions are established                  and if the actual number of BGP RTC neighbors is the one we expect.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>@anta_test\n@check_bgp_family_enable(\"rtc\")\nasync def verify_bgp_rtc_count(\n    device: InventoryDevice, result: TestResult, number: int\n) -&gt; TestResult:\n\"\"\"\n    Verifies all RTC BGP sessions are established (default VRF)\n    and the actual number of BGP RTC neighbors is the one we expect (default VRF).\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        number (int): The expected number of BGP RTC neighbors (default VRF).\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the `number` parameter is missing\n        * result = \"success\" if all RTC BGP sessions are established\n                             and if the actual number of BGP RTC neighbors is the one we expect.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    if not number:\n        result.is_skipped(\n            \"verify_bgp_rtc_count could not run because number was not supplied\"\n        )\n        return result\n\n    response = await device.session.cli(command=\"show bgp rt-membership summary\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    peers = response[\"vrfs\"][\"default\"][\"peers\"]\n    non_established_peers = [\n        peer\n        for peer, peer_dict in peers.items()\n        if peer_dict[\"peerState\"] != \"Established\"\n    ]\n\n    if not non_established_peers and len(peers) == number:\n        result.is_success()\n    else:\n        result.is_failure()\n        if len(peers) != number:\n            result.is_failure(f\"Expecting {number} BGP RTC peers and got {len(peers)}\")\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.bgp/#anta.tests.routing.bgp.verify_bgp_rtc_state","title":"<code>verify_bgp_rtc_state(device, result)</code>  <code>async</code>","text":"<p>Verifies all RTC BGP sessions are established (default VRF).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if no BGP RTC peers are returned by the device</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if all RTC BGP sessions are Established.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/bgp.py</code> <pre><code>@anta_test\n@check_bgp_family_enable(\"rtc\")\nasync def verify_bgp_rtc_state(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\"\"\"\n    Verifies all RTC BGP sessions are established (default VRF).\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if no BGP RTC peers are returned by the device\n        * result = \"success\" if all RTC BGP sessions are Established.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show bgp rt-membership summary\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    peers = response[\"vrfs\"][\"default\"][\"peers\"]\n    non_established_peers = [\n        peer\n        for peer, peer_dict in peers.items()\n        if peer_dict[\"peerState\"] != \"Established\"\n    ]\n\n    if not non_established_peers:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"The following RTC peers are not established: {non_established_peers}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.generic/","title":"Generic","text":""},{"location":"api/tests.routing.generic/#anta-catalog-for-routing-generic-tests","title":"ANTA catalog for routing-generic tests","text":"<p>Generic routing test functions</p>"},{"location":"api/tests.routing.generic/#anta.tests.routing.generic.verify_bfd","title":"<code>verify_bfd(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no BFD peer in down state (all VRF, IPv4 neighbors).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if routing-table size is OK</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/generic.py</code> <pre><code>@anta_test\nasync def verify_bfd(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\"\"\"\n    Verifies there is no BFD peer in down state (all VRF, IPv4 neighbors).\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if routing-table size is OK\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    response = await device.session.cli(command=\"show bfd peers\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n    has_failed: bool = False\n    for vrf in response[\"vrfs\"]:\n        for neighbor in response[\"vrfs\"][vrf][\"ipv4Neighbors\"]:\n            for interface in response[\"vrfs\"][vrf][\"ipv4Neighbors\"][neighbor][\n                \"peerStats\"\n            ]:\n                if (\n                    response[\"vrfs\"][vrf][\"ipv4Neighbors\"][neighbor][\"peerStats\"][\n                        interface\n                    ][\"status\"]\n                    != \"up\"\n                ):\n                    intf_state = response[\"vrfs\"][vrf][\"ipv4Neighbors\"][neighbor][\n                        \"peerStats\"\n                    ][interface][\"status\"]\n                    intf_name = response[\"vrfs\"][vrf][\"ipv4Neighbors\"][neighbor][\n                        \"peerStats\"\n                    ][interface]\n                    has_failed = True\n                    result.is_failure(\n                        f\"bfd state on interface {intf_name} is {intf_state} (expected up)\"\n                    )\n    if has_failed is False:\n        result.is_success()\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.generic/#anta.tests.routing.generic.verify_routing_protocol_model","title":"<code>verify_routing_protocol_model(device, result, model='multi-agent')</code>  <code>async</code>","text":"<p>Verifies the configured routing protocol model is the one we expect. And if there is no mismatch between the configured and operating routing protocol model.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>model(str)</code> <p>Expected routing protocol model (multi-agent or ribd). Default is multi-agent</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the test <code>model</code> parameter is missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if routing model is well configured</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/generic.py</code> <pre><code>@anta_test\nasync def verify_routing_protocol_model(\n    device: InventoryDevice, result: TestResult, model: str = \"multi-agent\"\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies the configured routing protocol model is the one we expect.\n    And if there is no mismatch between the configured and operating routing protocol model.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        model(str): Expected routing protocol model (multi-agent or ribd). Default is multi-agent\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the test `model` parameter is missing\n        * result = \"success\" if routing model is well configured\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    if not model:\n        result.is_skipped(\n            \"verify_routing_protocol_model was not run as no model was given\"\n        )\n        return result\n\n    response = await device.session.cli(\n        command={\"cmd\": \"show ip route summary\", \"revision\": 3}, ofmt=\"json\"\n    )\n    logger.debug(f\"query result is: {response}\")\n    configured_model = response[\"protoModelStatus\"][\"configuredProtoModel\"]\n    operating_model = response[\"protoModelStatus\"][\"operatingProtoModel\"]\n    if configured_model == operating_model == model:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"routing model is misconfigured: configured:{configured_model} - \"\n            f\"operating:{operating_model} - expected:{model} \"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.generic/#anta.tests.routing.generic.verify_routing_table_size","title":"<code>verify_routing_table_size(device, result, minimum, maximum)</code>  <code>async</code>","text":"<p>Verifies the size of the IP routing table (default VRF). Should be between the two provided thresholds.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>minimum(int)</code> <p>Expected minimum routing table (default VRF) size.</p> required <code>maximum(int)</code> <p>Expected maximum routing table (default VRF) size.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the test <code>minimum</code> or <code>maximum</code> parameters are missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if routing-table size is correct</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/generic.py</code> <pre><code>@anta_test\nasync def verify_routing_table_size(\n    device: InventoryDevice, result: TestResult, minimum: int, maximum: int\n) -&gt; TestResult:\n\"\"\"\n    Verifies the size of the IP routing table (default VRF).\n    Should be between the two provided thresholds.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        minimum(int): Expected minimum routing table (default VRF) size.\n        maximum(int): Expected maximum routing table (default VRF) size.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the test `minimum` or `maximum` parameters are missing\n        * result = \"success\" if routing-table size is correct\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    if not minimum or not maximum:\n        result.is_skipped(\n            \"verify_routing_table_size was not run as no \"\n            \"minimum or maximum were given\"\n        )\n        return result\n    response = await device.session.cli(\n        command={\"cmd\": \"show ip route summary\", \"revision\": 3}, ofmt=\"json\"\n    )\n    logger.debug(f\"query result is: {response}\")\n    total_routes = int(response[\"vrfs\"][\"default\"][\"totalRoutes\"])\n    if minimum &lt;= total_routes &lt;= maximum:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"routing-table has {total_routes} routes and not between min ({minimum}) and maximum ({maximum})\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.ospf/","title":"OSPF","text":""},{"location":"api/tests.routing.ospf/#anta-catalog-for-routing-ospf-tests","title":"ANTA catalog for routing-ospf tests","text":"<p>OSPF test functions</p>"},{"location":"api/tests.routing.ospf/#anta.tests.routing.ospf.verify_ospf_count","title":"<code>verify_ospf_count(device, result, number)</code>  <code>async</code>","text":"<p>Verifies the number of OSPF neighbors in FULL state is the one we expect.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>number</code> <code>int</code> <p>The expected number of OSPF neighbors in FULL state.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipeed\u201d if the <code>number</code> parameter is missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if device has correct number of devices</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/ospf.py</code> <pre><code>@anta_test\nasync def verify_ospf_count(\n    device: InventoryDevice, result: TestResult, number: int\n) -&gt; TestResult:\n\"\"\"\n    Verifies the number of OSPF neighbors in FULL state is the one we expect.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        number (int): The expected number of OSPF neighbors in FULL state.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipeed\" if the `number` parameter is missing\n        * result = \"success\" if device has correct number of devices\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    if not number:\n        result.is_skipped(\n            \"verify_igmp_snooping_vlans was not run as no number was given\"\n        )\n        return result\n\n    response = await device.session.cli(\n        command=\"show ip ospf neighbor | exclude  Address\", ofmt=\"text\"\n    )\n    logger.debug(f\"query result is: {response}\")\n    if len(response) == 0:\n        result.is_skipped(\"no OSPF neighbor found\")\n        return result\n    response_data = response.count(\"FULL\")\n    if response_data.count(\"FULL\") == number:\n        result.is_success()\n    else:\n        result.is_failure(\n            f'device has {response_data.count(\"FULL\")} neighbors (expected {number}'\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.routing.ospf/#anta.tests.routing.ospf.verify_ospf_state","title":"<code>verify_ospf_state(device, result)</code>  <code>async</code>","text":"<p>Verifies all OSPF neighbors are in FULL state.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if all OSPF neighbors are FULL.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/routing/ospf.py</code> <pre><code>@anta_test\nasync def verify_ospf_state(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\"\"\"\n    Verifies all OSPF neighbors are in FULL state.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if all OSPF neighbors are FULL.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    response = await device.session.cli(\n        command=\"show ip ospf neighbor | exclude FULL|Address\", ofmt=\"text\"\n    )\n    logger.debug(f\"query result is: {response}\")\n    if len(response) == 0:\n        result.is_skipped(\"no OSPF neighbor found\")\n        return result\n    if response.count(\"\\n\") == 0:\n        result.is_success()\n    else:\n        result.is_failure(\"Some neighbors are not correctly configured.\")\n\n    return result\n</code></pre>"},{"location":"api/tests.software/","title":"Software","text":""},{"location":"api/tests.software/#anta-catalog-for-software-tests","title":"ANTA catalog for software tests","text":"<p>Test functions related to the EOS software</p>"},{"location":"api/tests.software/#anta.tests.software.verify_eos_extensions","title":"<code>verify_eos_extensions(device, result)</code>  <code>async</code>","text":"<p>Verifies all EOS extensions installed on the device are enabled for boot persistence.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if the device has all installed its EOS extensions enabled for boot persistence.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/software.py</code> <pre><code>@anta_test\nasync def verify_eos_extensions(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\"\"\"\n    Verifies all EOS extensions installed on the device are enabled for boot persistence.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if the device has all installed its EOS extensions enabled for boot persistence.\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(commands=[\"show extensions\", \"show boot-extensions\"], ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    installed_extensions = []\n    boot_extensions = []\n    for extension in response[0][\"extensions\"]:\n        if response[0][\"extensions\"][extension][\"status\"] == \"installed\":\n            installed_extensions.append(extension)\n    for extension in response[1][\"extensions\"]:\n        extension = extension.strip(\"\\n\")\n        if extension == \"\":\n            pass\n        else:\n            boot_extensions.append(extension)\n    installed_extensions.sort()\n    boot_extensions.sort()\n    if installed_extensions == boot_extensions:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"Missing EOS extensions: installed {installed_extensions} / configured: {boot_extensions}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.software/#anta.tests.software.verify_eos_version","title":"<code>verify_eos_version(device, result, versions=None)</code>  <code>async</code>","text":"<p>Verifies the device is running one of the allowed EOS version.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>versions</code> <code>list</code> <p>List of allowed EOS versions.</p> <code>None</code> <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the <code>version</code> parameter is missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if EOS version is valid against versions</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/software.py</code> <pre><code>@anta_test\nasync def verify_eos_version(device: InventoryDevice, result: TestResult, versions: Optional[List[str]] = None) -&gt; TestResult:\n\"\"\"\n    Verifies the device is running one of the allowed EOS version.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        versions (list): List of allowed EOS versions.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the `version` parameter is missing\n        * result = \"success\" if EOS version is valid against versions\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    if not versions:\n        result.is_skipped(\"verify_eos_version was not run as no versions were given\")\n        return result\n\n    response = await device.session.cli(command=\"show version\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    if response[\"version\"] in versions:\n        result.is_success()\n    else:\n        result.is_failure(\n            f'device is running version {response[\"version\"]} not in expected versions: {versions}'\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.software/#anta.tests.software.verify_field_notice_44_resolution","title":"<code>verify_field_notice_44_resolution(device, result)</code>  <code>async</code>","text":"<p>Verifies the device is using an Aboot version that fix the bug discussed in the field notice 44 (Aboot manages system settings prior to EOS initialization).</p> <p>https://www.arista.com/en/support/advisories-notices/field-notice/8756-field-notice-44</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if aboot is running valid version</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/software.py</code> <pre><code>@skip_on_platforms([\"cEOSLab\"])\n@anta_test\nasync def verify_field_notice_44_resolution(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\"\"\"\n    Verifies the device is using an Aboot version that fix the bug discussed\n    in the field notice 44 (Aboot manages system settings prior to EOS initialization).\n\n    https://www.arista.com/en/support/advisories-notices/field-notice/8756-field-notice-44\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if aboot is running valid version\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    response = await device.session.cli(command=\"show version detail\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    devices = [\n        \"DCS-7010T-48\",\n        \"DCS-7010T-48-DC\",\n        \"DCS-7050TX-48\",\n        \"DCS-7050TX-64\",\n        \"DCS-7050TX-72\",\n        \"DCS-7050TX-72Q\",\n        \"DCS-7050TX-96\",\n        \"DCS-7050TX2-128\",\n        \"DCS-7050SX-64\",\n        \"DCS-7050SX-72\",\n        \"DCS-7050SX-72Q\",\n        \"DCS-7050SX2-72Q\",\n        \"DCS-7050SX-96\",\n        \"DCS-7050SX2-128\",\n        \"DCS-7050QX-32S\",\n        \"DCS-7050QX2-32S\",\n        \"DCS-7050SX3-48YC12\",\n        \"DCS-7050CX3-32S\",\n        \"DCS-7060CX-32S\",\n        \"DCS-7060CX2-32S\",\n        \"DCS-7060SX2-48YC6\",\n        \"DCS-7160-48YC6\",\n        \"DCS-7160-48TC6\",\n        \"DCS-7160-32CQ\",\n        \"DCS-7280SE-64\",\n        \"DCS-7280SE-68\",\n        \"DCS-7280SE-72\",\n        \"DCS-7150SC-24-CLD\",\n        \"DCS-7150SC-64-CLD\",\n        \"DCS-7020TR-48\",\n        \"DCS-7020TRA-48\",\n        \"DCS-7020SR-24C2\",\n        \"DCS-7020SRG-24C2\",\n        \"DCS-7280TR-48C6\",\n        \"DCS-7280TRA-48C6\",\n        \"DCS-7280SR-48C6\",\n        \"DCS-7280SRA-48C6\",\n        \"DCS-7280SRAM-48C6\",\n        \"DCS-7280SR2K-48C6-M\",\n        \"DCS-7280SR2-48YC6\",\n        \"DCS-7280SR2A-48YC6\",\n        \"DCS-7280SRM-40CX2\",\n        \"DCS-7280QR-C36\",\n        \"DCS-7280QRA-C36S\",\n    ]\n    variants = [\"-SSD-F\", \"-SSD-R\", \"-M-F\", \"-M-R\", \"-F\", \"-R\"]\n\n    model = response[\"modelName\"]\n    for variant in variants:\n        model = model.replace(variant, \"\")\n    if model not in devices:\n        result.is_skipped(\"device is not impacted by FN044\")\n        return result\n\n    for component in response[\"details\"][\"components\"]:\n        if component[\"name\"] == \"Aboot\":\n            aboot_version = component[\"version\"].split(\"-\")[2]\n    result.is_success()\n    if aboot_version.startswith(\"4.0.\") and int(aboot_version.split(\".\")[2]) &lt; 7:\n        result.is_failure(\n            f\"device is running incorrect version of aboot ({aboot_version})\"\n        )\n    elif aboot_version.startswith(\"4.1.\") and int(aboot_version.split(\".\")[2]) &lt; 1:\n        result.is_failure(\n            f\"device is running incorrect version of aboot ({aboot_version})\"\n        )\n    elif aboot_version.startswith(\"6.0.\") and int(aboot_version.split(\".\")[2]) &lt; 9:\n        result.is_failure(\n            f\"device is running incorrect version of aboot ({aboot_version})\"\n        )\n    elif aboot_version.startswith(\"6.1.\") and int(aboot_version.split(\".\")[2]) &lt; 7:\n        result.is_failure(\n            f\"device is running incorrect version of aboot ({aboot_version})\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.software/#anta.tests.software.verify_terminattr_version","title":"<code>verify_terminattr_version(device, result, versions=None)</code>  <code>async</code>","text":"<p>Verifies the device is running one of the allowed TerminAttr version.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>versions</code> <code>list</code> <p>List of allowed TerminAttr versions.</p> <code>None</code> <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the <code>versions</code> parameter is missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if TerminAttr version is valid against versions</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/software.py</code> <pre><code>@anta_test\nasync def verify_terminattr_version(\n    device: InventoryDevice, result: TestResult, versions: Optional[List[str]] = None\n) -&gt; TestResult:\n\"\"\"\n    Verifies the device is running one of the allowed TerminAttr version.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        versions (list): List of allowed TerminAttr versions.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the `versions` parameter is missing\n        * result = \"success\" if TerminAttr version is valid against versions\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    if not versions:\n        result.is_skipped(\n            \"verify_terminattr_version was not run as no versions were given\"\n        )\n        return result\n\n    response = await device.session.cli(command=\"show version detail\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n\n    response_data = response[\"details\"][\"packages\"][\"TerminAttr-core\"][\"version\"]\n    if response_data in versions:\n        result.is_success()\n    else:\n        result.is_failure(\n            f\"device is running TerminAttr version {response_data} and is not in the allowed list: {versions}\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.system/","title":"System","text":""},{"location":"api/tests.system/#anta-catalog-for-system-tests","title":"ANTA catalog for system tests","text":"<p>Test functions related to system-level features and protocols</p>"},{"location":"api/tests.system/#anta.tests.system.verify_agent_logs","title":"<code>verify_agent_logs(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no agent crash reported on the device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if there is no agent crash</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/system.py</code> <pre><code>@anta_test\nasync def verify_agent_logs(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\"\"\"\n    Verifies there is no agent crash reported on the device.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if there is no agent crash\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show agent logs crash\", ofmt=\"text\")\n    logger.debug(f\"query result is: {response}\")\n    if len(response) == 0:\n        result.is_success()\n    else:\n        result.is_failure(f\"device reported some agent crashes: {response}\")\n\n    return result\n</code></pre>"},{"location":"api/tests.system/#anta.tests.system.verify_coredump","title":"<code>verify_coredump(device, result)</code>  <code>async</code>","text":"<p>Verifies there is no core file.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if device has no core-dump</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/system.py</code> <pre><code>@anta_test\nasync def verify_coredump(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\"\"\"\n    Verifies there is no core file.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if device has no core-dump\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    device.assert_enable_password_is_not_none(\"verify_coredump\")\n\n    response = await device.session.cli(\n        commands=[\n            {\"cmd\": \"enable\", \"input\": str(device.enable_password)},\n            \"bash timeout 10 ls /var/core\",\n        ],\n        ofmt=\"text\",\n    )\n    logger.debug(f\"query result is: {response}\")\n    response_data = response[1]\n    if len(response_data) == 0:\n        result.is_success()\n    else:\n        result.is_failure(f\"Core-dump(s) have been found: {response_data}\")\n\n    return result\n</code></pre>"},{"location":"api/tests.system/#anta.tests.system.verify_cpu_utilization","title":"<code>verify_cpu_utilization(device, result)</code>  <code>async</code>","text":"<p>Verifies the CPU utilization is less than 75%.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if CPU usage is lower than 75%</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/system.py</code> <pre><code>@anta_test\nasync def verify_cpu_utilization(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\"\"\"\n    Verifies the CPU utilization is less than 75%.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if CPU usage is lower than 75%\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    response = await device.session.cli(command=\"show processes top once\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n    response_data = response[\"cpuInfo\"][\"%Cpu(s)\"][\"idle\"]\n    if response_data &gt; 25:\n        result.is_success()\n    else:\n        result.is_failure(f\"device reported a high CPU utilization ({response_data}%)\")\n\n    return result\n</code></pre>"},{"location":"api/tests.system/#anta.tests.system.verify_filesystem_utilization","title":"<code>verify_filesystem_utilization(device, result)</code>  <code>async</code>","text":"<p>Verifies each partition on the disk is used less than 75%.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if disk is used less than 75%</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/system.py</code> <pre><code>@anta_test\nasync def verify_filesystem_utilization(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\n\"\"\"\n    Verifies each partition on the disk is used less than 75%.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if disk is used less than 75%\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    response = await device.session.cli(\n        commands=[\n            {\"cmd\": \"enable\", \"input\": device.enable_password},\n            \"bash timeout 10 df -h\",\n        ],\n        ofmt=\"text\",\n    )\n    logger.debug(f\"query result is: {response}\")\n    result.is_success()\n    for line in response[1].split(\"\\n\")[1:]:\n        if (\n            \"loop\" not in line\n            and len(line) &gt; 0\n            and int(line.split()[4].replace(\"%\", \"\")) &gt; 75\n        ):\n            result.is_failure(\n                f'mount point {line} is higher than 75% (reprted {int(line.split()[4].replace(\" % \", \"\"))})'\n            )\n\n    return result\n</code></pre>"},{"location":"api/tests.system/#anta.tests.system.verify_memory_utilization","title":"<code>verify_memory_utilization(device, result)</code>  <code>async</code>","text":"<p>Verifies the memory utilization is less than 75%.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if memory usage is lower than 75%</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/system.py</code> <pre><code>@anta_test\nasync def verify_memory_utilization(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\"\"\"\n    Verifies the memory utilization is less than 75%.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if memory usage is lower than 75%\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    response = await device.session.cli(command=\"show version\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n    memory_usage = float(response[\"memFree\"]) / float(response[\"memTotal\"])\n    if memory_usage &gt; 0.25:\n        result.is_success()\n    else:\n        result.is_failure(f\"device report a high memory usage: {memory_usage*100}%\")\n\n    return result\n</code></pre>"},{"location":"api/tests.system/#anta.tests.system.verify_ntp","title":"<code>verify_ntp(device, result)</code>  <code>async</code>","text":"<p>Verifies NTP is synchronised.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if synchronized with NTP server</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/system.py</code> <pre><code>@anta_test\nasync def verify_ntp(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\n\"\"\"\n    Verifies NTP is synchronised.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if synchronized with NTP server\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    response = await device.session.cli(command=\"show ntp status\", ofmt=\"text\")\n    logger.debug(f\"query result is: {response}\")\n    if response.split(\"\\n\")[0].split(\" \")[0] == \"synchronised\":\n        result.is_success()\n    else:\n        data = response.split(\"\\n\")[0]\n        result.is_failure(f\"not sync with NTP server ({data})\")\n\n    return result\n</code></pre>"},{"location":"api/tests.system/#anta.tests.system.verify_reload_cause","title":"<code>verify_reload_cause(device, result)</code>  <code>async</code>","text":"<p>Verifies the last reload of the device was requested by a user.</p> <p>Test considers the following messages as normal and will return success. Failure is for other messages * Reload requested by the user. * Reload requested after FPGA upgrade</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if reload cause is standard</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/system.py</code> <pre><code>@anta_test\nasync def verify_reload_cause(\n    device: InventoryDevice, result: TestResult\n) -&gt; TestResult:\n\"\"\"\n    Verifies the last reload of the device was requested by a user.\n\n    Test considers the following messages as normal and will return success. Failure is for other messages\n    * Reload requested by the user.\n    * Reload requested after FPGA upgrade\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if reload cause is standard\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    response = await device.session.cli(command=\"show reload cause\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n    if \"resetCauses\" not in response.keys() or len(response[\"resetCauses\"]) == 0:\n        result.is_error(\"no reload cause available\")\n        return result\n\n    response_data = response.get(\"resetCauses\")[0].get(\"description\")\n    if response_data in [\n        \"Reload requested by the user.\",\n        \"Reload requested after FPGA upgrade\",\n    ]:\n        result.is_success()\n    else:\n        result.is_failure(f\"Reload cause is {response_data}\")\n\n    return result\n</code></pre>"},{"location":"api/tests.system/#anta.tests.system.verify_syslog","title":"<code>verify_syslog(device, result)</code>  <code>async</code>","text":"<p>Verifies the device had no syslog message with a severity of warning (or a more severe message) during the last 7 days.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if syslog has no WARNING message</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/system.py</code> <pre><code>@anta_test\nasync def verify_syslog(device: InventoryDevice, result: TestResult) -&gt; TestResult:\n\"\"\"\n    Verifies the device had no syslog message with a severity of warning (or a more severe message)\n    during the last 7 days.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"success\" if syslog has no WARNING message\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n    \"\"\"\n    response = await device.session.cli(\n        command=\"show logging last 7 days threshold warnings\", ofmt=\"text\"\n    )\n    logger.debug(f\"query result is: {response}\")\n    if len(response) == 0:\n        result.is_success()\n    else:\n        result.is_failure(\n            \"Device has some log messages with a severity WARNING or higher\"\n        )\n\n    return result\n</code></pre>"},{"location":"api/tests.system/#anta.tests.system.verify_uptime","title":"<code>verify_uptime(device, result, minimum=None)</code>  <code>async</code>","text":"<p>Verifies the device uptime is higher than a value.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>InventoryDevice</code> <p>InventoryDevice instance containing all devices information.</p> required <code>minimum</code> <code>int</code> <p>Minimum uptime in seconds.</p> <code>None</code> <p>Returns:</p> Type Description <code>TestResult</code> <p>TestResult instance with</p> <code>TestResult</code> <ul> <li>result = \u201cunset\u201d if the test has not been executed</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cskipped\u201d if the <code>minimum</code> parameter is  missing</li> </ul> <code>TestResult</code> <ul> <li>result = \u201csuccess\u201d if uptime is greater than minimun</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cfailure\u201d otherwise.</li> </ul> <code>TestResult</code> <ul> <li>result = \u201cerror\u201d if any exception is caught</li> </ul> Source code in <code>anta/tests/system.py</code> <pre><code>@anta_test\nasync def verify_uptime(\n    device: InventoryDevice, result: TestResult, minimum: Optional[int] = None\n) -&gt; TestResult:\n\"\"\"\n    Verifies the device uptime is higher than a value.\n\n    Args:\n        device (InventoryDevice): InventoryDevice instance containing all devices information.\n        minimum (int): Minimum uptime in seconds.\n\n    Returns:\n        TestResult instance with\n        * result = \"unset\" if the test has not been executed\n        * result = \"skipped\" if the `minimum` parameter is  missing\n        * result = \"success\" if uptime is greater than minimun\n        * result = \"failure\" otherwise.\n        * result = \"error\" if any exception is caught\n\n    \"\"\"\n    if not minimum:\n        result.is_skipped(\"verify_uptime was not run as no minimum were given\")\n        return result\n\n    response = await device.session.cli(command=\"show uptime\", ofmt=\"json\")\n    logger.debug(f\"query result is: {response}\")\n    if response[\"upTime\"] &gt; minimum:\n        result.is_success()\n    else:\n        result.is_failure(f\"Uptime is {response['upTime']}\")\n\n    return result\n</code></pre>"}]}